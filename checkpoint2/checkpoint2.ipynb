{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 2 Notebook\n",
    "\n",
    "__TODO__:\n",
    "- fill this cell in with info, results, insights from our EDA \n",
    "- preprocess: create preprocessing pipeline, store all code into script, then run script to preprocess all data and store into pickle\n",
    "- analysis: need \"3 hypothesis tests\" to validate hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- imports ------------- #\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pickle\n",
    "import librosa\n",
    "import scipy.signal as signal\n",
    "import polars as pl\n",
    "import soundfile as sf \n",
    "from typing import Union, List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ macros ------------ #\n",
    "SAMPLE_RATE = 16e3\n",
    "ORG_CSV_PATH = './ReCANVo/dataset_file_directory.csv'\n",
    "RENAME_CSV_PATH = './ReCANVo/renamed_metadata.csv'\n",
    "AUDIO_DIR = './ReCANVo/'\n",
    "\n",
    "\n",
    "# ----------------------- preprocessing functions ----------------------- #\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf  # Added soundfile for audio writing\n",
    "import scipy.signal as signal\n",
    "import os\n",
    "\n",
    "def save_audio_comparison(original_y: np.ndarray, \n",
    "                           cleaned_y: np.ndarray, \n",
    "                           sr: int, \n",
    "                           filename: str, \n",
    "                           output_dir: str = 'audio_comparisons') -> None:\n",
    "    \"\"\"\n",
    "    Save original and cleaned audio files for side-by-side comparison.\n",
    "\n",
    "    Parameters:\n",
    "        original_y (np.ndarray): Original audio time series\n",
    "        cleaned_y (np.ndarray): Cleaned audio time series\n",
    "        sr (int): Sampling rate\n",
    "        filename (str): Base filename for saved audio files\n",
    "        output_dir (str): Directory to save comparison audio files\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    original_path = os.path.join(output_dir, f\"{base_name}_original.wav\")\n",
    "    cleaned_path = os.path.join(output_dir, f\"{base_name}_cleaned.wav\")\n",
    "\n",
    "    sf.write(original_path, original_y, sr)\n",
    "    sf.write(cleaned_path, cleaned_y, sr)\n",
    "\n",
    "def clean_audio(y: np.ndarray, \n",
    "                sr: int, \n",
    "                denoise: bool = True, \n",
    "                remove_silence: bool = True,\n",
    "                normalize: bool = True,\n",
    "                min_silence_duration: float = 0.3,\n",
    "                silence_threshold: float = -40) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Enhanced audio cleaning function tailored for voice recordings of autistic individuals.\n",
    "\n",
    "    Parameters:\n",
    "        y (np.ndarray): Input audio time series\n",
    "        sr (int): Sampling rate\n",
    "        denoise (bool): Apply noise reduction\n",
    "        remove_silence (bool): Remove long silent segments\n",
    "        normalize (bool): Normalize audio amplitude\n",
    "        min_silence_duration (float): Minimum duration of silence to remove (in seconds)\n",
    "        silence_threshold (float): Decibel threshold for silence detection\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Cleaned audio time series\n",
    "    \"\"\"\n",
    "    cleaned_audio = y.copy()\n",
    "\n",
    "    if normalize:\n",
    "        cleaned_audio = librosa.util.normalize(cleaned_audio)\n",
    "\n",
    "    # Noise reduction using spectral gating\n",
    "    if denoise:\n",
    "        # Compute short-time Fourier transform (STFT)\n",
    "        stft = librosa.stft(cleaned_audio)\n",
    "        \n",
    "        # Compute magnitude and phase\n",
    "        mag, phase = librosa.magphase(stft)\n",
    "        \n",
    "        # Compute the noise threshold\n",
    "        noise_threshold = np.median(mag) * 0.5\n",
    "        \n",
    "        # Create a soft mask to reduce noise\n",
    "        mask = mag > noise_threshold\n",
    "        \n",
    "        # Apply the mask\n",
    "        cleaned_stft = stft * mask\n",
    "        \n",
    "        # Convert back to time domain\n",
    "        cleaned_audio = librosa.istft(cleaned_stft)\n",
    "\n",
    "    # Remove long silent segments\n",
    "    if remove_silence:\n",
    "        # Compute the frame size and hop length for silence detection\n",
    "        frame_length = int(sr * min_silence_duration)\n",
    "        hop_length = frame_length // 2\n",
    "\n",
    "        # Detect non-silent frames\n",
    "        non_silent_frames = librosa.effects.split(\n",
    "            cleaned_audio, \n",
    "            top_db=abs(silence_threshold), \n",
    "            frame_length=frame_length, \n",
    "            hop_length=hop_length\n",
    "        )\n",
    "\n",
    "        # Reconstruct audio from non-silent segments\n",
    "        cleaned_audio = np.concatenate([\n",
    "            cleaned_audio[start:end] for start, end in non_silent_frames\n",
    "        ])\n",
    "\n",
    "    # Apply gentle high-pass filter to reduce low-frequency noise\n",
    "    b, a = signal.butter(6, 80 / (sr/2), btype='high')\n",
    "    cleaned_audio = signal.filtfilt(b, a, cleaned_audio)\n",
    "\n",
    "    return cleaned_audio\n",
    "\n",
    "def load_audio_metadata(csv_path: str,\n",
    "                        audio_dir: str,\n",
    "                        limit: Union[int, None] = None,\n",
    "                        clean_audio_params: dict = None,\n",
    "                        save_comparisons: bool = False,\n",
    "                        comparison_dir: str = 'audio_comparisons') -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads audio files from directory and returns a DataFrame with cleaned waveform and metadata.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file containing data.\n",
    "        audio_dir (str): Directory where audio files are stored.\n",
    "        limit (int, optional): Number of rows to load. If None, loads all.\n",
    "        clean_audio_params (dict, optional): Parameters for audio cleaning.\n",
    "        save_comparisons (bool): Whether to save original vs cleaned audio files\n",
    "        comparison_dir (str): Directory to save comparison audio files\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame with columns: Filename, Audio, ID, Label, Duration, Index\n",
    "    \"\"\"\n",
    "    df = pl.read_csv(csv_path)\n",
    "    if limit:\n",
    "        df = df.head(limit)\n",
    "\n",
    "    # Default cleaning parameters if not provided\n",
    "    default_clean_params = {\n",
    "        'denoise': True,\n",
    "        'remove_silence': True,\n",
    "        'normalize': True,\n",
    "        'min_silence_duration': 0.3,\n",
    "        'silence_threshold': -40\n",
    "    }\n",
    "    clean_params = default_clean_params if clean_audio_params is None else {**default_clean_params, **clean_audio_params}\n",
    "\n",
    "    audio_data = []\n",
    "\n",
    "    if save_comparisons is True:\n",
    "        comparison_count = len(df)  \n",
    "    else:\n",
    "        comparison_count = 0  \n",
    "\n",
    "    for idx, row in enumerate(df.iter_rows(named=True)):\n",
    "        file_name = row['Filename']\n",
    "        file_path = os.path.join(audio_dir, file_name)\n",
    "\n",
    "        # Load original audio\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Clean audio\n",
    "        cleaned_y = clean_audio(y, sr, **clean_params)\n",
    "\n",
    "        if save_comparisons and idx < comparison_count:\n",
    "            save_audio_comparison(\n",
    "                original_y=y, \n",
    "                cleaned_y=cleaned_y, \n",
    "                sr=sr, \n",
    "                filename=file_name,\n",
    "                output_dir=comparison_dir\n",
    "            )\n",
    "        \n",
    "        duration = len(cleaned_y) / sr\n",
    "\n",
    "        audio_data.append((\n",
    "            file_name,\n",
    "            cleaned_y.tolist(),\n",
    "            row['ID'],\n",
    "            row['Label'],\n",
    "            duration,\n",
    "            row['Index']\n",
    "        ))\n",
    "\n",
    "    audio_df = pl.DataFrame(\n",
    "        audio_data,\n",
    "        schema=[\"Filename\", \"Audio\", \"ID\", \"Label\", \"Duration\", \"Index\"],\n",
    "        orient='row'\n",
    "    )\n",
    "\n",
    "    return audio_df\n",
    "\n",
    "\n",
    "def rename_audio_files(csv_path: str,\n",
    "                       audio_dir: str,\n",
    "                       output_csv: str = \"renamed_metadata.csv\") -> None:\n",
    "    \"\"\"\n",
    "    Renames audio files based on Participant and Label and saves new metadata.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the input metadata CSV.\n",
    "        audio_dir (str): Directory containing audio files.\n",
    "        output_csv (str): Filename for the output metadata CSV.\n",
    "    \"\"\"\n",
    "    df = pl.read_csv(csv_path)\n",
    "    renamed_files = []\n",
    "    file_counts = {}\n",
    "\n",
    "    for file in df.iter_rows(named=True):\n",
    "        org_name = file['Filename']\n",
    "        id = file['Participant']\n",
    "        label = file['Label']\n",
    "\n",
    "        key = (id, label)\n",
    "        file_counts[key] = file_counts.get(key, 0) + 1\n",
    "        index = file_counts[key]\n",
    "\n",
    "        new_name = f\"{id}_{label}_{index}.wav\"\n",
    "        old_path = os.path.join(audio_dir, org_name)\n",
    "        new_path = os.path.join(audio_dir, new_name)\n",
    "\n",
    "        if not os.path.exists(old_path):\n",
    "            print(f\"âŒ File not found: {old_path}. Skipping renaming process.\")\n",
    "            return  # Exit the function immediately if any file is missing\n",
    "\n",
    "        os.rename(old_path, new_path)\n",
    "        renamed_files.append((new_name, id, label, index))\n",
    "\n",
    "    # If renaming was successful, save the updated metadata\n",
    "    renamed_df = pl.DataFrame(renamed_files, schema=[\"Filename\", \"ID\", \"Label\", \"Index\"], orient=\"row\")\n",
    "    output_path = os.path.join(audio_dir, output_csv)\n",
    "    renamed_df.write_csv(output_path)\n",
    "    \n",
    "\n",
    "def compute_or_load_global_stats(ys: List[np.ndarray],\n",
    "                                 sr: int,\n",
    "                                 n_mels: int = 128,\n",
    "                                 method: str = \"zscore\",\n",
    "                                 stats_file: str = \"global_stats.json\",\n",
    "                                 force_recompute: bool = False) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Computes or loads global normalization stats for Mel spectrograms.\n",
    "\n",
    "    Parameters:\n",
    "        ys (List[np.ndarray]): List of raw audio waveforms.\n",
    "        sr (int): Sample rate.\n",
    "        n_mels (int): Number of Mel bands.\n",
    "        method (str): 'zscore' or 'minmax'.\n",
    "        stats_file (str): Path to save/load stats JSON.\n",
    "        force_recompute (bool): If True, recomputes even if file exists.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: Stats dictionary (mean/std or min/max).\n",
    "    \"\"\"\n",
    "\n",
    "    if not force_recompute and os.path.exists(stats_file):\n",
    "        print(f\"ðŸ—‚ï¸ Loading global stats from {stats_file}\")\n",
    "        with open(stats_file, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    print(f\"ðŸ“Š Computing global stats with method '{method}'...\")\n",
    "    all_values = []\n",
    "\n",
    "    for y in ys:\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "        S_db = librosa.power_to_db(S, ref=np.max)\n",
    "        all_values.append(S_db.flatten())\n",
    "\n",
    "    all_values = np.concatenate(all_values)\n",
    "    stats = {}\n",
    "\n",
    "    if method == \"zscore\":\n",
    "        stats = {\n",
    "            \"mean\": float(np.mean(all_values)),\n",
    "            \"std\": float(np.std(all_values))\n",
    "        }\n",
    "    elif method == \"minmax\":\n",
    "        stats = {\n",
    "            \"min\": float(np.min(all_values)),\n",
    "            \"max\": float(np.max(all_values))\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Use 'zscore' or 'minmax'.\")\n",
    "\n",
    "    # Save stats to file\n",
    "    with open(stats_file, \"w\") as f:\n",
    "        json.dump(stats, f)\n",
    "        print(f\"ðŸ’¾ Saved global stats to {stats_file}\")\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "\n",
    "def audio_to_spectrogram(y: np.ndarray,\n",
    "                         sr: int,\n",
    "                         n_mels: int = 128,\n",
    "                         target_length: int = 128,\n",
    "                         normalization: str = \"minmax\",\n",
    "                         normalize_scope: str = \"sample\",  # \"sample\" or \"global\"\n",
    "                         global_stats: dict = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts a raw audio waveform into a normalized, fixed-size Mel spectrogram.\n",
    "\n",
    "    Parameters:\n",
    "        y (np.ndarray): Raw audio waveform.\n",
    "        sr (int): Sample rate of the audio.\n",
    "        n_mels (int): Number of Mel bands.\n",
    "        target_length (int): Number of time steps to pad/crop to.\n",
    "        normalization (str): 'minmax' or 'zscore'.\n",
    "        normalize_scope (str): 'sample' for per-sample normalization,\n",
    "                               'global' for dataset-wide using global_stats.\n",
    "        global_stats (dict): Required if normalize_scope='global'. Should contain\n",
    "                             'mean' and 'std' or 'min' and 'max'.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Mel spectrogram of shape (n_mels, target_length).\n",
    "    \"\"\"\n",
    "\n",
    "    def _normalize(S_db: np.ndarray, method: str, scope: str, stats: dict = None):\n",
    "        if scope == \"sample\":\n",
    "            if method == \"minmax\":\n",
    "                return (S_db - S_db.min()) / (S_db.max() - S_db.min())\n",
    "            elif method == \"zscore\":\n",
    "                mean = np.mean(S_db)\n",
    "                std = np.std(S_db)\n",
    "                return (S_db - mean) / std\n",
    "        elif scope == \"global\":\n",
    "            if stats is None:\n",
    "                raise ValueError(\"Global normalization requires global_stats.\")\n",
    "            if method == \"minmax\":\n",
    "                return (S_db - stats[\"min\"]) / (stats[\"max\"] - stats[\"min\"])\n",
    "            elif method == \"zscore\":\n",
    "                return (S_db - stats[\"mean\"]) / stats[\"std\"]\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported normalization scope. Use 'sample' or 'global'.\")\n",
    "\n",
    "    def _pad_or_crop(S: np.ndarray, target_len: int):\n",
    "        current_len = S.shape[1]\n",
    "        if current_len < target_len:\n",
    "            pad_width = target_len - current_len\n",
    "            return np.pad(S, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            return S[:, :target_len]\n",
    "\n",
    "    # Compute Mel spectrogram and convert to dB\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    # Normalize\n",
    "    S_norm = _normalize(S_db, method=normalization, scope=normalize_scope, stats=global_stats)\n",
    "\n",
    "    # Fix shape\n",
    "    S_fixed = _pad_or_crop(S_norm, target_len=target_length)\n",
    "\n",
    "    return S_fixed\n",
    "\n",
    "\n",
    "def pipeline(rename: bool = False, \n",
    "             limit: Union[int, None] = None,\n",
    "             clean_audio_params: dict = None,\n",
    "             save_comparisons: bool = False,\n",
    "             save_path: str = \"processed_dataset.parquet\") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Pipeline to run all preprocessing functions with timing and optional audio cleaning.\n",
    "    Only supports saving to .parquet (not CSV) to handle arrays properly.\n",
    "    \"\"\"\n",
    "    print(\"ðŸš€ Starting preprocessing pipeline...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    if rename:\n",
    "        t0 = time.time()\n",
    "        rename_audio_files(\n",
    "            csv_path=ORG_CSV_PATH,\n",
    "            audio_dir=AUDIO_DIR,\n",
    "        )\n",
    "        print(f\"ðŸ“ rename_audio_files completed in {time.time() - t0:.2f} seconds\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    df = load_audio_metadata(\n",
    "        csv_path=RENAME_CSV_PATH,\n",
    "        audio_dir=AUDIO_DIR,\n",
    "        limit=limit,\n",
    "        clean_audio_params=clean_audio_params,\n",
    "        save_comparisons=save_comparisons\n",
    "    )\n",
    "    print(f\"â³ load_audio_metadata completed in {time.time() - t0:.2f} seconds\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    stats = compute_or_load_global_stats(df[\"Audio\"].to_numpy(), sr=SAMPLE_RATE)\n",
    "    print(f\"ðŸ§® compute_or_load_global_stats completed in {time.time() - t0:.2f} seconds\")\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ Computed Statistics:\")\n",
    "    for k, v in stats.items(): \n",
    "        print(f\"  {k}: {v}\")\n",
    "    print()\n",
    "\n",
    "    t0 = time.time()\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"Audio\").map_elements(lambda y: audio_to_spectrogram(\n",
    "            y=np.array(y),\n",
    "            sr=SAMPLE_RATE,\n",
    "            normalization='zscore',\n",
    "            normalize_scope='global',\n",
    "            global_stats=stats\n",
    "        ), return_dtype=pl.Object).alias(\"Spectrogram\")\n",
    "    ])\n",
    "    print(f\"ðŸ”Š Spectrogram generation completed in {time.time() - t0:.2f} seconds\")\n",
    "    \n",
    "    print(f\"ðŸ Full pipeline completed in {time.time() - start:.2f} seconds\\n\")\n",
    "    print(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- visualization functions ----------------------- #\n",
    "# Function to plot spectrograms for each label using Polars\n",
    "def plot_spectrograms_per_label(df):\n",
    "    # Group the dataframe by label\n",
    "    grouped = df.group_by(\"Label\")\n",
    "    \n",
    "    # Iterate through each label group\n",
    "    for label_group in grouped:\n",
    "        # Extract the label and its corresponding spectrograms\n",
    "        label = label_group[0]\n",
    "        spectrograms = label_group[1].get_column(\"Spectrogram\")\n",
    "        \n",
    "        # Create a figure for this label\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(f\"Spectrograms for Label: {label}\")\n",
    "        \n",
    "        # Plot all spectrograms for this label\n",
    "        for spectrogram in spectrograms:\n",
    "            plt.imshow(np.array(spectrogram), \n",
    "                       aspect=\"auto\", \n",
    "                       origin=\"lower\", \n",
    "                       cmap=\"viridis\", \n",
    "                       alpha=0.6)\n",
    "        \n",
    "        # Add colorbar and labels\n",
    "        plt.colorbar(label=\"Intensity (dB)\")\n",
    "        plt.xlabel(\"Time Frames\")\n",
    "        plt.ylabel(\"Frequency Bins\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- visualization functions ----------------------- #\n",
    "# Function to plot spectrograms for each label using Polars\n",
    "def plot_spectrograms_per_label_pkl(df):\n",
    "    # Group the dataframe by label\n",
    "    grouped = df.group_by(\"Label\")\n",
    "\n",
    "    # Iterate through each label group\n",
    "    for label_group in grouped:\n",
    "        # Extract the label and its corresponding spectrograms\n",
    "        label = label_group[0]\n",
    "        spectrograms = label_group[1].get_column(\"Spectrogram\")\n",
    "\n",
    "        # Create a figure for this label\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(f\"Spectrograms for Label: {label}\")\n",
    "\n",
    "        # Plot all spectrograms for this label\n",
    "        for spectrogram in spectrograms:\n",
    "            # Convert Polars List(List(Float32)) to a NumPy array\n",
    "            spectrogram_np = np.array(spectrogram.to_list(), dtype=np.float32)\n",
    "            \n",
    "            # Ensure it's a 2D array before plotting\n",
    "            if spectrogram_np.ndim == 2:\n",
    "                plt.imshow(spectrogram_np, aspect=\"auto\", origin=\"lower\", cmap=\"viridis\", alpha=0.6)\n",
    "            else:\n",
    "                print(f\"Skipping spectrogram for label {label}, unexpected shape: {spectrogram_np.shape}\")\n",
    "\n",
    "        # Add colorbar and labels\n",
    "        plt.colorbar(label=\"Intensity (dB)\")\n",
    "        plt.xlabel(\"Time Frames\")\n",
    "        plt.ylabel(\"Frequency Bins\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting preprocessing pipeline...\n",
      "â³ load_audio_metadata completed in 10.77 seconds\n",
      "ðŸ—‚ï¸ Loading global stats from global_stats.json\n",
      "ðŸ§® compute_or_load_global_stats completed in 0.01 seconds\n",
      "\n",
      "ðŸ“ˆ Computed Statistics:\n",
      "  mean: -55.975612227106474\n",
      "  std: 18.55726476893056\n",
      "\n",
      "ðŸ”Š Spectrogram generation completed in 5.91 seconds\n",
      "ðŸ Full pipeline completed in 16.69 seconds\n",
      "\n",
      "shape: (1_200, 7)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ Filename          â”† Audio        â”† ID  â”† Label             â”† Duration â”† Index â”† Spectrogram      â”‚\n",
      "â”‚ ---               â”† ---          â”† --- â”† ---               â”† ---      â”† ---   â”† ---              â”‚\n",
      "â”‚ str               â”† list[f64]    â”† str â”† str               â”† f64      â”† i64   â”† object           â”‚\n",
      "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ P01_dysregulation â”† [-0.107696,  â”† P01 â”† dysregulation-sic â”† 0.263991 â”† 1     â”† [[ 1.7136524     â”‚\n",
      "â”‚ -sick_1.wav       â”† -0.120435, â€¦ â”†     â”† k                 â”†          â”†       â”† 1.54897187  0.8â€¦ â”‚\n",
      "â”‚                   â”† 0.004â€¦       â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P01_dysregulation â”† [0.145757,   â”† P01 â”† dysregulation-sic â”† 0.931995 â”† 2     â”† [[ 1.12985372    â”‚\n",
      "â”‚ -sick_2.wav       â”† 0.148597, â€¦  â”†     â”† k                 â”†          â”†       â”† 0.95378244  0.4â€¦ â”‚\n",
      "â”‚                   â”† 0.00491â€¦     â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P01_dysregulation â”† [0.034168,   â”† P01 â”† dysregulation-sic â”† 1.144989 â”† 3     â”† [[ 0.31567814    â”‚\n",
      "â”‚ -sick_3.wav       â”† 0.022339, â€¦  â”†     â”† k                 â”†          â”†       â”† 0.21322916 -0.4â€¦ â”‚\n",
      "â”‚                   â”† 0.05369â€¦     â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P01_dysregulation â”† [-0.005132,  â”† P01 â”† dysregulation-sic â”† 3.647982 â”† 4     â”† [[ 0.36459158    â”‚\n",
      "â”‚ -sick_4.wav       â”† -0.012268, â€¦ â”†     â”† k                 â”†          â”†       â”† 0.38200755  0.0â€¦ â”‚\n",
      "â”‚                   â”† 0.001â€¦       â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P01_dysregulation â”† [-0.002284,  â”† P01 â”† dysregulation-sic â”† 0.405986 â”† 5     â”† [[ 1.21694593    â”‚\n",
      "â”‚ -sick_5.wav       â”† -0.002782, â€¦ â”†     â”† k                 â”†          â”†       â”† 1.03654392  0.2â€¦ â”‚\n",
      "â”‚                   â”† -0.07â€¦       â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ â€¦                 â”† â€¦            â”† â€¦   â”† â€¦                 â”† â€¦        â”† â€¦     â”† â€¦                â”‚\n",
      "â”‚ P01_selftalk_558. â”† [0.003,      â”† P01 â”† selftalk          â”† 0.646984 â”† 558   â”† [[ 1.02758553    â”‚\n",
      "â”‚ wav               â”† 0.008613, â€¦  â”†     â”†                   â”†          â”†       â”† 0.84566928  0.0â€¦ â”‚\n",
      "â”‚                   â”† 0.003187]    â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P01_selftalk_559. â”† [-0.00069,   â”† P01 â”† selftalk          â”† 5.455011 â”† 559   â”† [[ 0.06897648    â”‚\n",
      "â”‚ wav               â”† -0.00082, â€¦  â”†     â”†                   â”†          â”†       â”† -0.12043663      â”‚\n",
      "â”‚                   â”† -0.0034â€¦     â”†     â”†                   â”†          â”†       â”† -0.7â€¦            â”‚\n",
      "â”‚ P01_selftalk_560. â”† [-0.012827,  â”† P01 â”† selftalk          â”† 0.324989 â”† 560   â”† [[ 1.03009388    â”‚\n",
      "â”‚ wav               â”† -0.01046, â€¦  â”†     â”†                   â”†          â”†       â”† 1.07201625  1.1â€¦ â”‚\n",
      "â”‚                   â”† -0.001â€¦      â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P01_selftalk_561. â”† [0.001232,   â”† P01 â”† selftalk          â”† 1.331995 â”† 561   â”† [[ 0.77829157    â”‚\n",
      "â”‚ wav               â”† 0.001533, â€¦  â”†     â”†                   â”†          â”†       â”† 0.96019664  0.9â€¦ â”‚\n",
      "â”‚                   â”† 0.00044â€¦     â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P01_selftalk_562. â”† [-0.011422,  â”† P01 â”† selftalk          â”† 1.042993 â”† 562   â”† [[ 0.84606322    â”‚\n",
      "â”‚ wav               â”† -0.012816, â€¦ â”†     â”†                   â”†          â”†       â”† 0.70022509 -0.0â€¦ â”‚\n",
      "â”‚                   â”† -0.00â€¦       â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "custom_clean_params = {\n",
    "    'denoise': False,\n",
    "    'remove_silence': False,\n",
    "    'min_silence_duration': 0.5,\n",
    "    'silence_threshold': -35\n",
    "}\n",
    "\n",
    "df = pipeline(\n",
    "    rename=False, \n",
    "    limit=1200,\n",
    "    clean_audio_params=custom_clean_params,\n",
    "    save_comparisons=False\n",
    ")\n",
    "\n",
    "# Save DataFrame as Pickl\n",
    "# df = df.with_columns([\n",
    "#     pl.col(\"Audio\").map_elements(lambda y: np.array(y, dtype=np.float32).tolist(), return_dtype=pl.List(pl.Float32)),\n",
    "#     pl.col(\"Spectrogram\").map_elements(lambda s: np.array(s, dtype=np.float32).tolist(), return_dtype=pl.List(pl.List(pl.Float32)))\n",
    "# ])\n",
    "# with open(\"processed_data.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle(path: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a Polars DataFrame from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the pickle file.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: The loaded Polars DataFrame.\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        df = pickle.load(f)\n",
    "    \n",
    "    if not isinstance(df, pl.DataFrame):\n",
    "        raise TypeError(\"Loaded object is not a Polars DataFrame.\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[String, List(Float32), String, String, Float64, Int64, List(List(Float32))]\n"
     ]
    }
   ],
   "source": [
    "df = open_pickle(\"./processed_data.pkl\")\n",
    "df\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrograms_per_label_pkl(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_pitch_extraction(audio_list, max_samples_per_batch=50, sr=16000):\n",
    "    \"\"\"\n",
    "    Efficiently extract pitch features for a batch of audio samples\n",
    "    \n",
    "    Args:\n",
    "        audio_list (list): List of audio arrays\n",
    "        max_samples_per_batch (int): Maximum number of samples to process\n",
    "        sr (int): Sampling rate\n",
    "    \n",
    "    Returns:\n",
    "        list: Pitch standard deviation for each audio sample\n",
    "    \"\"\"\n",
    "    # Randomly sample if batch is too large\n",
    "    if len(audio_list) > max_samples_per_batch:\n",
    "        np.random.seed(42)  # Reproducible sampling\n",
    "        sample_indices = np.random.choice(len(audio_list), max_samples_per_batch, replace=False)\n",
    "        audio_list = [audio_list[i] for i in sample_indices]\n",
    "    \n",
    "    pitch_stds = []\n",
    "    for audio_array in audio_list:\n",
    "        try:\n",
    "            # Convert to numpy array\n",
    "            audio_array = np.asarray(audio_array, dtype=np.float64)\n",
    "            \n",
    "            # Extract pitch using PYIN\n",
    "            f0, voiced_flag, _ = librosa.pyin(\n",
    "                audio_array, \n",
    "                fmin=librosa.note_to_hz('C2'),\n",
    "                fmax=librosa.note_to_hz('C7'),\n",
    "                sr=sr\n",
    "            )\n",
    "            \n",
    "            # Filter for voiced segments\n",
    "            f0_voiced = f0[voiced_flag]\n",
    "            \n",
    "            # Calculate pitch std, handle empty case\n",
    "            pitch_std = float(np.std(f0_voiced)) if len(f0_voiced) > 0 else 0.0\n",
    "            pitch_stds.append(pitch_std)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Pitch extraction error: {e}\")\n",
    "            pitch_stds.append(0.0)\n",
    "    \n",
    "    return pitch_stds\n",
    "\n",
    "def pitch_variability_test(df, target_labels=['frustrated', 'delighted']):\n",
    "    \"\"\"\n",
    "    Perform efficient pitch variability hypothesis test\n",
    "    \n",
    "    Args:\n",
    "        df (pl.DataFrame): Input DataFrame\n",
    "        target_labels (list): Labels to compare\n",
    "    \n",
    "    Returns:\n",
    "        dict: Statistical test results\n",
    "    \"\"\"\n",
    "    # Group audio by label\n",
    "    label_audio_groups = {}\n",
    "    for label in target_labels:\n",
    "        # Extract audio for each label\n",
    "        label_audio_groups[label] = df.filter(pl.col(\"Label\") == label)[\"Audio\"].to_list()\n",
    "    \n",
    "    # Batch pitch extraction\n",
    "    label_pitch_stds = {}\n",
    "    for label, audio_list in label_audio_groups.items():\n",
    "        label_pitch_stds[label] = batch_pitch_extraction(audio_list)\n",
    "        \n",
    "        # Print basic stats\n",
    "        pitch_array = np.array(label_pitch_stds[label])\n",
    "        print(f\"{label} samples: {len(pitch_array)}\")\n",
    "        print(f\"  Mean pitch std: {np.mean(pitch_array):.4f}\")\n",
    "        print(f\"  Std of pitch std: {np.std(pitch_array):.4f}\")\n",
    "    \n",
    "    # Perform statistical tests\n",
    "    label1_data = label_pitch_stds[target_labels[0]]\n",
    "    label2_data = label_pitch_stds[target_labels[1]]\n",
    "    \n",
    "    # Mann-Whitney U Test\n",
    "    u_statistic, p_value = scipy.stats.mannwhitneyu(\n",
    "        label1_data, \n",
    "        label2_data, \n",
    "        alternative='two-sided'\n",
    "    )\n",
    "    \n",
    "    # Effect size calculation (Cohen's d)\n",
    "    mean1, std1 = np.mean(label1_data), np.std(label1_data)\n",
    "    mean2, std2 = np.mean(label2_data), np.std(label2_data)\n",
    "    \n",
    "    # Pooled standard deviation\n",
    "    pooled_std = np.sqrt(((len(label1_data) - 1) * std1**2 + \n",
    "                          (len(label2_data) - 1) * std2**2) / \n",
    "                         (len(label1_data) + len(label2_data) - 2))\n",
    "    \n",
    "    # Cohen's d\n",
    "    cohens_d = (mean1 - mean2) / pooled_std\n",
    "    \n",
    "    # Prepare results\n",
    "    results = {\n",
    "        'Mann-Whitney U Statistic': u_statistic,\n",
    "        'p-value': p_value,\n",
    "        'Cohen\\'s d': cohens_d,\n",
    "        'Mean Difference': mean1 - mean2,\n",
    "        'Significant': p_value < 0.05\n",
    "    }\n",
    "    \n",
    "    # Print comprehensive results\n",
    "    print(\"\\n=== Hypothesis Test Results ===\")\n",
    "    for key, value in results.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frustrated samples: 50\n",
      "  Mean pitch std: 35.3110\n",
      "  Std of pitch std: 59.3552\n",
      "delighted samples: 50\n",
      "  Mean pitch std: 40.8195\n",
      "  Std of pitch std: 73.6350\n",
      "\n",
      "=== Hypothesis Test Results ===\n",
      "Mann-Whitney U Statistic: 1345.0\n",
      "p-value: 0.5147457320739065\n",
      "Cohen's d: -0.08236728492343201\n",
      "Mean Difference: -5.508500881557481\n",
      "Significant: False\n"
     ]
    }
   ],
   "source": [
    "results = pitch_variability_test(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
