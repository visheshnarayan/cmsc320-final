{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 2 Notebook\n",
    "\n",
    "__TODO__:\n",
    "- fill this cell in with info, results, insights from our EDA \n",
    "- preprocess: create preprocessing pipeline, store all code into script, then run script to preprocess all data and store into pickle\n",
    "- analysis: need \"3 hypothesis tests\" to validate hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- imports ------------- #\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import polars as pl\n",
    "from typing import Union, List, Dict\n",
    "import json\n",
    "import time\n",
    "\n",
    "# ------------ macros ------------ #\n",
    "SAMPLE_RATE = 16e3\n",
    "\n",
    "\n",
    "# ----------------------- preprocessing functions ----------------------- #\n",
    "def rename_audio_files(csv_path: str,\n",
    "                       audio_dir: str,\n",
    "                       output_csv: str = \"renamed_metadata.csv\") -> None:\n",
    "    \"\"\"\n",
    "    Renames audio files based on Participant and Label and saves new metadata.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the input metadata CSV.\n",
    "        audio_dir (str): Directory containing audio files.\n",
    "        output_csv (str): Filename for the output metadata CSV.\n",
    "    \"\"\"\n",
    "    df = pl.read_csv(csv_path)\n",
    "    renamed_files = []\n",
    "    file_counts = {}\n",
    "\n",
    "    for file in df.iter_rows(named=True):\n",
    "        org_name = file['Filename']\n",
    "        id = file['Participant']\n",
    "        label = file['Label']\n",
    "\n",
    "        key = (id, label)\n",
    "        file_counts[key] = file_counts.get(key, 0) + 1\n",
    "        index = file_counts[key]\n",
    "\n",
    "        new_name = f\"{id}_{label}_{index}.wav\"\n",
    "        old_path = os.path.join(audio_dir, org_name)\n",
    "        new_path = os.path.join(audio_dir, new_name)\n",
    "\n",
    "        os.rename(old_path, new_path)\n",
    "        renamed_files.append((new_name, id, label, index))\n",
    "\n",
    "    renamed_df = pl.DataFrame(renamed_files, schema=[\"Filename\", \"ID\", \"Label\", \"Index\"], orient=\"row\")\n",
    "    output_path = os.path.join(audio_dir, output_csv)\n",
    "    renamed_df.write_csv(output_path)\n",
    "\n",
    "\n",
    "def load_audio_metadata(csv_path: str,\n",
    "                        audio_dir: str,\n",
    "                        limit: Union[int, None] = None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads audio files from directory and returns a DataFrame with waveform and metadata.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file containing data.\n",
    "        audio_dir (str): Directory where audio files are stored.\n",
    "        limit (int, optional): Number of rows to load. If None, loads all.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame with columns: Filename, Audio, ID, Label, Duration, Index\n",
    "    \"\"\"\n",
    "    df = pl.read_csv(csv_path)\n",
    "    if limit:\n",
    "        df = df.head(limit)\n",
    "\n",
    "    audio_data = []\n",
    "\n",
    "    for row in df.iter_rows(named=True):\n",
    "        file_name = row['Filename']\n",
    "        file_path = os.path.join(audio_dir, file_name)\n",
    "\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        duration = len(y) / sr\n",
    "\n",
    "        audio_data.append((\n",
    "            file_name,\n",
    "            y.tolist(),\n",
    "            row['ID'],\n",
    "            row['Label'],\n",
    "            duration,\n",
    "            row['Index']\n",
    "        ))\n",
    "\n",
    "    audio_df = pl.DataFrame(\n",
    "        audio_data,\n",
    "        schema=[\"Filename\", \"Audio\", \"ID\", \"Label\", \"Duration\", \"Index\"],\n",
    "        orient='row'\n",
    "    )\n",
    "\n",
    "    return audio_df\n",
    "\n",
    "\n",
    "def compute_or_load_global_stats(ys: List[np.ndarray],\n",
    "                                 sr: int,\n",
    "                                 n_mels: int = 128,\n",
    "                                 method: str = \"zscore\",\n",
    "                                 stats_file: str = \"global_stats.json\",\n",
    "                                 force_recompute: bool = False) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Computes or loads global normalization stats for Mel spectrograms.\n",
    "\n",
    "    Parameters:\n",
    "        ys (List[np.ndarray]): List of raw audio waveforms.\n",
    "        sr (int): Sample rate.\n",
    "        n_mels (int): Number of Mel bands.\n",
    "        method (str): 'zscore' or 'minmax'.\n",
    "        stats_file (str): Path to save/load stats JSON.\n",
    "        force_recompute (bool): If True, recomputes even if file exists.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: Stats dictionary (mean/std or min/max).\n",
    "    \"\"\"\n",
    "\n",
    "    if not force_recompute and os.path.exists(stats_file):\n",
    "        print(f\"🗂️ Loading global stats from {stats_file}\")\n",
    "        with open(stats_file, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    print(f\"📊 Computing global stats with method '{method}'...\")\n",
    "    all_values = []\n",
    "\n",
    "    for y in ys:\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "        S_db = librosa.power_to_db(S, ref=np.max)\n",
    "        all_values.append(S_db.flatten())\n",
    "\n",
    "    all_values = np.concatenate(all_values)\n",
    "    stats = {}\n",
    "\n",
    "    if method == \"zscore\":\n",
    "        stats = {\n",
    "            \"mean\": float(np.mean(all_values)),\n",
    "            \"std\": float(np.std(all_values))\n",
    "        }\n",
    "    elif method == \"minmax\":\n",
    "        stats = {\n",
    "            \"min\": float(np.min(all_values)),\n",
    "            \"max\": float(np.max(all_values))\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Use 'zscore' or 'minmax'.\")\n",
    "\n",
    "    # Save stats to file\n",
    "    with open(stats_file, \"w\") as f:\n",
    "        json.dump(stats, f)\n",
    "        print(f\"💾 Saved global stats to {stats_file}\")\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "\n",
    "def audio_to_spectrogram(y: np.ndarray,\n",
    "                         sr: int,\n",
    "                         n_mels: int = 128,\n",
    "                         target_length: int = 128,\n",
    "                         normalization: str = \"minmax\",\n",
    "                         normalize_scope: str = \"sample\",  # \"sample\" or \"global\"\n",
    "                         global_stats: dict = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts a raw audio waveform into a normalized, fixed-size Mel spectrogram.\n",
    "\n",
    "    Parameters:\n",
    "        y (np.ndarray): Raw audio waveform.\n",
    "        sr (int): Sample rate of the audio.\n",
    "        n_mels (int): Number of Mel bands.\n",
    "        target_length (int): Number of time steps to pad/crop to.\n",
    "        normalization (str): 'minmax' or 'zscore'.\n",
    "        normalize_scope (str): 'sample' for per-sample normalization,\n",
    "                               'global' for dataset-wide using global_stats.\n",
    "        global_stats (dict): Required if normalize_scope='global'. Should contain\n",
    "                             'mean' and 'std' or 'min' and 'max'.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Mel spectrogram of shape (n_mels, target_length).\n",
    "    \"\"\"\n",
    "\n",
    "    def _normalize(S_db: np.ndarray, method: str, scope: str, stats: dict = None):\n",
    "        if scope == \"sample\":\n",
    "            if method == \"minmax\":\n",
    "                return (S_db - S_db.min()) / (S_db.max() - S_db.min())\n",
    "            elif method == \"zscore\":\n",
    "                mean = np.mean(S_db)\n",
    "                std = np.std(S_db)\n",
    "                return (S_db - mean) / std\n",
    "        elif scope == \"global\":\n",
    "            if stats is None:\n",
    "                raise ValueError(\"Global normalization requires global_stats.\")\n",
    "            if method == \"minmax\":\n",
    "                return (S_db - stats[\"min\"]) / (stats[\"max\"] - stats[\"min\"])\n",
    "            elif method == \"zscore\":\n",
    "                return (S_db - stats[\"mean\"]) / stats[\"std\"]\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported normalization scope. Use 'sample' or 'global'.\")\n",
    "\n",
    "    def _pad_or_crop(S: np.ndarray, target_len: int):\n",
    "        current_len = S.shape[1]\n",
    "        if current_len < target_len:\n",
    "            pad_width = target_len - current_len\n",
    "            return np.pad(S, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            return S[:, :target_len]\n",
    "\n",
    "    # Compute Mel spectrogram and convert to dB\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    # Normalize\n",
    "    S_norm = _normalize(S_db, method=normalization, scope=normalize_scope, stats=global_stats)\n",
    "\n",
    "    # Fix shape\n",
    "    S_fixed = _pad_or_crop(S_norm, target_len=target_length)\n",
    "\n",
    "    return S_fixed\n",
    "\n",
    "\n",
    "\n",
    "def pipeline(rename: bool=False, limit: Union[int, None] = None):\n",
    "    \"\"\"\n",
    "    Pipeline to run all preprocessing functions with timing.\n",
    "    \"\"\"\n",
    "    print(\"🚀 Starting preprocessing pipeline...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    # Step 1: Rename files\n",
    "    if rename:\n",
    "        t0 = time.time()\n",
    "        rename_audio_files(\n",
    "            \"/Users/visheshnarayan/Documents/Code/School/CMSC320/cmsc320-final/ReCANVo/dataset_file_directory.csv\",\n",
    "            \"/Users/visheshnarayan/Documents/Code/School/CMSC320/cmsc320-final/ReCANVo/\"\n",
    "        )\n",
    "        print(f\"📝 rename_audio_files completed in {time.time() - t0:.2f} seconds\")\n",
    "\n",
    "    # Step 2: Load audio metadata\n",
    "    t0 = time.time()\n",
    "    df = load_audio_metadata(\n",
    "        csv_path=\"/Users/visheshnarayan/Documents/Code/School/CMSC320/cmsc320-final/ReCANVo/renamed_metadata.csv\",\n",
    "        audio_dir=\"/Users/visheshnarayan/Documents/Code/School/CMSC320/cmsc320-final/ReCANVo/\",\n",
    "        limit=limit\n",
    "    )\n",
    "    print(f\"⏳ load_audio_metadata completed in {time.time() - t0:.2f} seconds\")\n",
    "\n",
    "    # Step 3: Compute or load global stats\n",
    "    t0 = time.time()\n",
    "    stats = compute_or_load_global_stats(df[\"Audio\"].to_numpy(), sr=SAMPLE_RATE)\n",
    "    print(f\"🧮 compute_or_load_global_stats completed in {time.time() - t0:.2f} seconds\")\n",
    "    \n",
    "    print(\"\\n📈 Computed Statistics:\")\n",
    "    for k, v in stats.items(): \n",
    "        print(f\"  {k}: {v}\")\n",
    "    print()\n",
    "\n",
    "    # Step 4: Compute spectrograms\n",
    "    t0 = time.time()\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"Audio\").map_elements(lambda y: audio_to_spectrogram(\n",
    "            y=np.array(y),\n",
    "            sr=SAMPLE_RATE,\n",
    "            normalization='zscore',\n",
    "            normalize_scope='global',\n",
    "            global_stats=stats\n",
    "        ), return_dtype=pl.Object).alias(\"Spectrogram\")\n",
    "    ])\n",
    "    print(f\"🔊 Spectrogram generation completed in {time.time() - t0:.2f} seconds\")\n",
    "\n",
    "    # Done\n",
    "    print(f\"\\n🏁 Full pipeline completed in {time.time() - start:.2f} seconds\\n\")\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting preprocessing pipeline...\n",
      "📝 rename_audio_files completed in 0.98 seconds\n",
      "⏳ load_audio_metadata completed in 206.69 seconds\n",
      "🗂️ Loading global stats from global_stats.json\n",
      "🧮 compute_or_load_global_stats completed in 0.15 seconds\n",
      "\n",
      "📈 Computed Statistics:\n",
      "  mean: -55.975612227106474\n",
      "  std: 18.55726476893056\n",
      "\n",
      "🔊 Spectrogram generation completed in 26.33 seconds\n",
      "\n",
      "🏁 Full pipeline completed in 234.17 seconds\n",
      "\n",
      "shape: (7_077, 7)\n",
      "┌───────────────────┬──────────────┬─────┬───────────────────┬──────────┬───────┬──────────────────┐\n",
      "│ Filename          ┆ Audio        ┆ ID  ┆ Label             ┆ Duration ┆ Index ┆ Spectrogram      │\n",
      "│ ---               ┆ ---          ┆ --- ┆ ---               ┆ ---      ┆ ---   ┆ ---              │\n",
      "│ str               ┆ list[f64]    ┆ str ┆ str               ┆ f64      ┆ i64   ┆ object           │\n",
      "╞═══════════════════╪══════════════╪═════╪═══════════════════╪══════════╪═══════╪══════════════════╡\n",
      "│ P01_dysregulation ┆ [-0.146042,  ┆ P01 ┆ dysregulation-sic ┆ 0.263991 ┆ 1     ┆ [[ 1.90314987    │\n",
      "│ -sick_1.wav       ┆ -0.152634, … ┆     ┆ k                 ┆          ┆       ┆ 1.55816024 -0.0… │\n",
      "│                   ┆ 0.006…       ┆     ┆                   ┆          ┆       ┆                  │\n",
      "│ P01_dysregulation ┆ [0.088348,   ┆ P01 ┆ dysregulation-sic ┆ 0.931995 ┆ 2     ┆ [[ 1.15689149    │\n",
      "│ -sick_2.wav       ┆ 0.091385, …  ┆     ┆ k                 ┆          ┆       ┆ 0.83036181  0.2… │\n",
      "│                   ┆ -0.1295…     ┆     ┆                   ┆          ┆       ┆                  │\n",
      "│ P01_dysregulation ┆ [0.035843,   ┆ P01 ┆ dysregulation-sic ┆ 1.144989 ┆ 3     ┆ [[-0.23412235    │\n",
      "│ -sick_3.wav       ┆ 0.024033, …  ┆     ┆ k                 ┆          ┆       ┆ -0.22180939      │\n",
      "│                   ┆ 0.21106…     ┆     ┆                   ┆          ┆       ┆ -0.4…            │\n",
      "│ P01_dysregulation ┆ [0.00676,    ┆ P01 ┆ dysregulation-sic ┆ 3.647982 ┆ 4     ┆ [[ 0.51460581    │\n",
      "│ -sick_4.wav       ┆ -0.000458, … ┆     ┆ k                 ┆          ┆       ┆ 0.31279042 -0.0… │\n",
      "│                   ┆ 0.05534…     ┆     ┆                   ┆          ┆       ┆                  │\n",
      "│ P01_dysregulation ┆ [0.028397,   ┆ P01 ┆ dysregulation-sic ┆ 0.405986 ┆ 5     ┆ [[ 0.55980165    │\n",
      "│ -sick_5.wav       ┆ 0.027649, …  ┆     ┆ k                 ┆          ┆       ┆ 0.38610811 -0.2… │\n",
      "│                   ┆ -0.3195…     ┆     ┆                   ┆          ┆       ┆                  │\n",
      "│ …                 ┆ …            ┆ …   ┆ …                 ┆ …        ┆ …     ┆ …                │\n",
      "│ P16_delighted_135 ┆ [0.0, 0.0, … ┆ P16 ┆ delighted         ┆ 1.046984 ┆ 135   ┆ [[-0.1850793     │\n",
      "│ .wav              ┆ -0.013916]   ┆     ┆                   ┆          ┆       ┆ 0.24888102  0.2… │\n",
      "│ P16_delighted_136 ┆ [0.014069,   ┆ P16 ┆ delighted         ┆ 0.643016 ┆ 136   ┆ [[ 0.35468619    │\n",
      "│ .wav              ┆ 0.009094, …  ┆     ┆                   ┆          ┆       ┆ 0.4770178   0.6… │\n",
      "│                   ┆ -0.0006…     ┆     ┆                   ┆          ┆       ┆                  │\n",
      "│ P16_delighted_137 ┆ [-0.003715,  ┆ P16 ┆ delighted         ┆ 0.773878 ┆ 137   ┆ [[-0.21028448    │\n",
      "│ .wav              ┆ -0.004659, … ┆     ┆                   ┆          ┆       ┆ -0.04781407      │\n",
      "│                   ┆ 0.022…       ┆     ┆                   ┆          ┆       ┆ 0.1…             │\n",
      "│ P16_delighted_138 ┆ [-0.002249,  ┆ P16 ┆ delighted         ┆ 0.747642 ┆ 138   ┆ [[ 0.69461725    │\n",
      "│ .wav              ┆ -0.004126, … ┆     ┆                   ┆          ┆       ┆ 0.9290602   0.8… │\n",
      "│                   ┆ 0.018…       ┆     ┆                   ┆          ┆       ┆                  │\n",
      "│ P16_delighted_139 ┆ [-0.013641,  ┆ P16 ┆ delighted         ┆ 1.278005 ┆ 139   ┆ [[-0.20681652    │\n",
      "│ .wav              ┆ -0.011871, … ┆     ┆                   ┆          ┆       ┆ 0.06343726  0.0… │\n",
      "│                   ┆ 0.010…       ┆     ┆                   ┆          ┆       ┆                  │\n",
      "└───────────────────┴──────────────┴─────┴───────────────────┴──────────┴───────┴──────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# set rename to False if files already renamed\n",
    "pipeline(\n",
    "    rename=True,\n",
    "    limit=None # processes all files \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
