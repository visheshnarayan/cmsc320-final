{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 2: Vocalization Feature Analysis/EDA for Non-Verbal Communication\n",
    "\n",
    "This notebook supports our broader project goal of developing techniques to detect and classify non-verbal vocalizations from autistic individuals.\n",
    "\n",
    "Specifically, this notebook focuses on:\n",
    "\n",
    "- Extracting acoustic features (e.g., pitch, MFCCs, spectrograms) from labeled vocal samples\n",
    "- Running statistical hypothesis tests to assess whether these features meaningfully differ across expressive intent labels (e.g., \"yes\" vs. \"no\", \"frustrated\" vs. \"delighted\")\n",
    "- Guiding downstream model development by identifying discriminative features that could improve classification performance\n",
    "\n",
    "The insights gained here help inform which audio characteristics are most relevant for modeling and how they correlate with the communicative intent behind each vocalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- imports ------------- #\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import pickle\n",
    "import librosa\n",
    "import scipy.signal as signal\n",
    "import soundfile as sf \n",
    "from typing import Union, List, Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before conducting any analysis or modeling, we perform a series of preprocessing steps to ensure all audio data is clean, standardized, and feature-rich. The goal is to prepare vocalization data from non-verbal individuals in a format suitable for feature extraction and machine learning workflows.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Audio Cleaning\n",
    "Raw audio signals are passed through a customizable cleaning pipeline that includes:\n",
    "\n",
    "- **Normalization** – Scales amplitude values to a consistent range.\n",
    "- **Noise Reduction** – Uses spectral gating to remove background noise.\n",
    "- **Silence Removal** – Removes low-energy segments using a dB threshold and frame-based segmentation.\n",
    "- **High-pass Filtering** – Reduces low-frequency hum and background noise.\n",
    "\n",
    "Optionally, the pipeline can **save both original and cleaned audio** for manual inspection.\n",
    "\n",
    "\n",
    "\n",
    "### 2. File Renaming & Metadata Generation\n",
    "Audio files are renamed using a consistent format:  \n",
    "`<Participant>_<Label>_<Index>.wav`  \n",
    "This enables easier traceability and lookup. The updated metadata is saved to a new CSV for downstream use.\n",
    "\n",
    "\n",
    "\n",
    "### 3. Feature Extraction – Mel Spectrograms\n",
    "Each cleaned audio waveform is converted into a **Mel spectrogram** (a time–frequency representation). We ensure consistency across samples by:\n",
    "\n",
    "- Using a fixed number of **Mel bands** (default: 128)\n",
    "- **Normalizing** each spectrogram using either:\n",
    "  - **Sample-level statistics** (mean/std or min/max per sample), or  \n",
    "  - **Global dataset statistics** (computed and optionally saved)\n",
    "- **Padding or cropping** spectrograms to a fixed temporal length for modeling\n",
    "\n",
    "\n",
    "\n",
    "### 4. Final Dataset Output\n",
    "The resulting dataset includes:\n",
    "\n",
    "- Cleaned waveform (`Audio`)\n",
    "- Metadata (`Label`, `Participant ID`, `Filename`, etc.)\n",
    "- Normalized spectrogram (`Spectrogram`)\n",
    "\n",
    "This processed data is returned as a **Polars DataFrame**, with an option to save in `.pkl` format (CSV is avoided due to unsupported nested data types like arrays).\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "These steps prepare the dataset for robust feature-based analysis and downstream ML/DL pipelines. The goal is to ensure that audio representations are:\n",
    "\n",
    "- Noise-free and consistent  \n",
    "- Normalized across the dataset  \n",
    "- Aligned in shape and scale  \n",
    "- Ready for hypothesis testing, embedding, or classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- macros ----------------------- #\n",
    "SAMPLE_RATE = 441e2\n",
    "ORG_CSV_PATH = './ReCANVo/dataset_file_directory.csv'\n",
    "RENAME_CSV_PATH = './ReCANVo/renamed_metadata.csv'\n",
    "AUDIO_DIR = './ReCANVo/'\n",
    "np.random.seed(42)  # Reproducible sampling\n",
    "\n",
    "# ----------------------- preprocessing functions ----------------------- #\n",
    "def rename_audio_files(csv_path: str,\n",
    "                       audio_dir: str,\n",
    "                       output_csv: str = \"renamed_metadata.csv\") -> None:\n",
    "    \"\"\"\n",
    "    Renames audio files based on Participant and Label and saves new metadata.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the input metadata CSV.\n",
    "        audio_dir (str): Directory containing audio files.\n",
    "        output_csv (str): Filename for the output metadata CSV.\n",
    "    \"\"\"\n",
    "    df = pl.read_csv(csv_path)\n",
    "    renamed_files = []\n",
    "    file_counts = {}\n",
    "\n",
    "    for file in df.iter_rows(named=True):\n",
    "        org_name = file['Filename']\n",
    "        id = file['Participant']\n",
    "        label = file['Label']\n",
    "\n",
    "        key = (id, label)\n",
    "        file_counts[key] = file_counts.get(key, 0) + 1\n",
    "        index = file_counts[key]\n",
    "\n",
    "        new_name = f\"{id}_{label}_{index}.wav\"\n",
    "        old_path = os.path.join(audio_dir, org_name)\n",
    "        new_path = os.path.join(audio_dir, new_name)\n",
    "\n",
    "        if not os.path.exists(old_path):\n",
    "            print(f\"❌ File not found: {old_path}. Skipping renaming process.\")\n",
    "            return  # Exit the function immediately if any file is missing\n",
    "\n",
    "        os.rename(old_path, new_path)\n",
    "        renamed_files.append((new_name, id, label, index))\n",
    "\n",
    "    # If renaming was successful, save the updated metadata\n",
    "    renamed_df = pl.DataFrame(renamed_files, schema=[\"Filename\", \"ID\", \"Label\", \"Index\"], orient=\"row\")\n",
    "    output_path = os.path.join(audio_dir, output_csv)\n",
    "    renamed_df.write_csv(output_path)\n",
    "    \n",
    "def save_audio_comparison(original_y: np.ndarray, \n",
    "                           cleaned_y: np.ndarray, \n",
    "                           sr: int, \n",
    "                           filename: str, \n",
    "                           output_dir: str = 'audio_comparisons') -> None:\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    original_path = os.path.join(output_dir, f\"{base_name}_original.wav\")\n",
    "    cleaned_path = os.path.join(output_dir, f\"{base_name}_cleaned.wav\")\n",
    "\n",
    "    sf.write(original_path, original_y, sr)\n",
    "    sf.write(cleaned_path, cleaned_y, sr)\n",
    "\n",
    "\n",
    "def clean_audio(y: np.ndarray, \n",
    "                sr: int, \n",
    "                denoise: bool = True, \n",
    "                remove_silence: bool = True,\n",
    "                normalize: bool = True,\n",
    "                min_silence_duration: float = 0.3,\n",
    "                silence_threshold: float = -40) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Enhanced audio cleaning function tailored for voice recordings of autistic individuals.\n",
    "\n",
    "    Parameters:\n",
    "        y (np.ndarray): Input audio time series\n",
    "        sr (int): Sampling rate\n",
    "        denoise (bool): Apply noise reduction\n",
    "        remove_silence (bool): Remove long silent segments\n",
    "        normalize (bool): Normalize audio amplitude\n",
    "        min_silence_duration (float): Minimum duration of silence to remove (in seconds)\n",
    "        silence_threshold (float): Decibel threshold for silence detection\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Cleaned audio time series\n",
    "    \"\"\"\n",
    "    if len(y) == 0:\n",
    "        return y  # Return empty if the input is empty\n",
    "\n",
    "    cleaned_audio = y.copy()\n",
    "\n",
    "    if normalize:\n",
    "        cleaned_audio = librosa.util.normalize(cleaned_audio)\n",
    "\n",
    "    # Noise reduction using spectral gating\n",
    "    if denoise:\n",
    "        stft = librosa.stft(cleaned_audio)   # Compute STFT with valid n_fft\n",
    "        mag, phase = librosa.magphase(stft)               # Magnitude and phase\n",
    "        noise_threshold = np.median(mag) * 0.5\n",
    "        mask = mag > noise_threshold                      # Apply noise threshold mask\n",
    "        cleaned_stft = stft * mask                        \n",
    "        cleaned_audio = librosa.istft(cleaned_stft)       # Convert back to time domain\n",
    "\n",
    "    # Remove long silent segments\n",
    "    if remove_silence:\n",
    "        frame_length = int(sr * min_silence_duration)\n",
    "        hop_length = max(1, frame_length // 2)  # Ensure hop_length is at least 1\n",
    "\n",
    "        non_silent_frames = librosa.effects.split(\n",
    "            cleaned_audio, \n",
    "            top_db=abs(silence_threshold), \n",
    "            frame_length=frame_length, \n",
    "            hop_length=hop_length\n",
    "        )\n",
    "\n",
    "        if len(non_silent_frames) == 0:\n",
    "            return np.array([])  # Return empty if all frames are silent\n",
    "\n",
    "        cleaned_audio = np.concatenate([\n",
    "            cleaned_audio[start:end] for start, end in non_silent_frames\n",
    "        ])\n",
    "\n",
    "    # Apply high-pass filter to reduce low-frequency noise\n",
    "    b, a = signal.butter(6, 80 / (sr/2), btype='high')\n",
    "    cleaned_audio = signal.filtfilt(b, a, cleaned_audio)\n",
    "\n",
    "    return cleaned_audio\n",
    "\n",
    "\n",
    "def load_audio_metadata(csv_path: str,\n",
    "                        audio_dir: str,\n",
    "                        limit: Union[int, None] = None,\n",
    "                        clean_audio_params: dict = None,\n",
    "                        save_comparisons: bool = False,\n",
    "                        comparison_dir: str = 'audio_comparisons') -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads audio metadata and processes files in parallel.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to CSV file with metadata.\n",
    "        audio_dir (str): Directory where audio files are stored.\n",
    "        limit (int, optional): Number of rows to load.\n",
    "        clean_audio_params (dict, optional): Parameters for cleaning.\n",
    "        save_comparisons (bool): Save original vs cleaned audio files.\n",
    "        comparison_dir (str): Directory for saved audio comparisons.\n",
    "    \n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame with processed audio metadata.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pl.read_csv(csv_path).drop_nulls(subset=['Filename'])\n",
    "\n",
    "    if limit:\n",
    "        df = df.head(limit)\n",
    "\n",
    "    # Default audio cleaning parameters\n",
    "    default_clean_params = {\n",
    "        'denoise': True,\n",
    "        'remove_silence': True,\n",
    "        'normalize': True,\n",
    "        'min_silence_duration': 0.3,\n",
    "        'silence_threshold': -40\n",
    "    }\n",
    "    clean_params = {**default_clean_params, **(clean_audio_params or {})}\n",
    "\n",
    "    # Prepare file processing queue \n",
    "    file_info_list = [\n",
    "        (row['Filename'], \n",
    "         os.path.join(audio_dir, row['Filename']), \n",
    "         clean_params, \n",
    "         save_comparisons, \n",
    "         comparison_dir, \n",
    "         row['ID'],\n",
    "         row['Label'],  \n",
    "         row['Index']) \n",
    "        for row in df.iter_rows(named=True)\n",
    "    ]\n",
    "\n",
    "    # Modify process_audio_file to handle the additional parameters\n",
    "    def process_audio_file(file_info: Tuple[str, str, dict, bool, str, int, str, int]) -> Union[Tuple[str, List[float], int, str, float, int], None]:\n",
    "        \"\"\"\n",
    "        Loads and processes an audio file.\n",
    "\n",
    "        Args:\n",
    "            file_info (Tuple): Contains filename, full path, cleaning params, saving options, ID, Label, and Index.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[str, List[float], int, str, float, int] | None: Processed audio metadata or None if failed.\n",
    "        \"\"\"\n",
    "        file_name, file_path, clean_params, save_comparisons, comparison_dir, file_id, label, index = file_info\n",
    "\n",
    "        y, sr = librosa.load(file_path, sr=SAMPLE_RATE)  \n",
    "        cleaned_y = clean_audio(y, sr, **clean_params)\n",
    "\n",
    "        if save_comparisons:\n",
    "            save_audio_comparison(y, cleaned_y, sr, file_name, comparison_dir)\n",
    "\n",
    "        duration = len(cleaned_y) / sr\n",
    "        return file_name, cleaned_y.tolist(), file_id, label, duration, index  \n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel processing\n",
    "    with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "        results = list(executor.map(process_audio_file, file_info_list))\n",
    "\n",
    "    # Filter out None values from failed processing\n",
    "    audio_data = [res for res in results if res]\n",
    "\n",
    "    return pl.DataFrame(audio_data, schema=[\"Filename\", \"Audio\", \"ID\", \"Label\", \"Duration\", \"Index\"], orient='row')\n",
    "\n",
    "\n",
    "def compute_or_load_global_stats(ys: List[np.ndarray],\n",
    "                                 sr: int=SAMPLE_RATE,\n",
    "                                 n_mels: int = 128,\n",
    "                                 method: str = \"zscore\",\n",
    "                                 stats_file: str = \"global_stats.json\",\n",
    "                                 force_recompute: bool = False) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Computes or loads global normalization stats for Mel spectrograms.\n",
    "\n",
    "    Parameters:\n",
    "        ys (List[np.ndarray]): List of raw audio waveforms.\n",
    "        sr (int): Sample rate.\n",
    "        n_mels (int): Number of Mel bands.\n",
    "        method (str): 'zscore' or 'minmax'.\n",
    "        stats_file (str): Path to save/load stats JSON.\n",
    "        force_recompute (bool): If True, recomputes even if file exists.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: Stats dictionary (mean/std or min/max).\n",
    "    \"\"\"\n",
    "\n",
    "    if not force_recompute and os.path.exists(stats_file):\n",
    "        print(f\"🗂️ Loading global stats from {stats_file}\")\n",
    "        with open(stats_file, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    print(f\"📊 Computing global stats with method '{method}'...\")\n",
    "    all_values = []\n",
    "\n",
    "    for y in ys:\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "        S_db = librosa.power_to_db(S, ref=np.max)\n",
    "        all_values.append(S_db.flatten())\n",
    "\n",
    "    all_values = np.concatenate(all_values)\n",
    "    stats = {}\n",
    "\n",
    "    if method == \"zscore\":\n",
    "        stats = {\n",
    "            \"mean\": float(np.mean(all_values)),\n",
    "            \"std\": float(np.std(all_values))\n",
    "        }\n",
    "    elif method == \"minmax\":\n",
    "        stats = {\n",
    "            \"min\": float(np.min(all_values)),\n",
    "            \"max\": float(np.max(all_values))\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Use 'zscore' or 'minmax'.\")\n",
    "\n",
    "    # Save stats to file\n",
    "    with open(stats_file, \"w\") as f:\n",
    "        json.dump(stats, f)\n",
    "        print(f\"💾 Saved global stats to {stats_file}\")\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def audio_to_spectrogram(y: np.ndarray,\n",
    "                         sr: int=SAMPLE_RATE,\n",
    "                         n_mels: int = 128,\n",
    "                         target_length: int = 128,\n",
    "                         normalization: str = \"minmax\",\n",
    "                         normalize_scope: str = \"sample\",  # \"sample\" or \"global\"\n",
    "                         global_stats: dict = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts a raw audio waveform into a normalized, fixed-size Mel spectrogram.\n",
    "\n",
    "    Parameters:\n",
    "        y (np.ndarray): Raw audio waveform.\n",
    "        sr (int): Sample rate of the audio.\n",
    "        n_mels (int): Number of Mel bands.\n",
    "        target_length (int): Number of time steps to pad/crop to.\n",
    "        normalization (str): 'minmax' or 'zscore'.\n",
    "        normalize_scope (str): 'sample' for per-sample normalization,\n",
    "                               'global' for dataset-wide using global_stats.\n",
    "        global_stats (dict): Required if normalize_scope='global'. Should contain\n",
    "                             'mean' and 'std' or 'min' and 'max'.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Mel spectrogram of shape (n_mels, target_length).\n",
    "    \"\"\"\n",
    "\n",
    "    def _normalize(S_db: np.ndarray, method: str, scope: str, stats: dict = None):\n",
    "        if scope == \"sample\":\n",
    "            if method == \"minmax\":\n",
    "                return (S_db - S_db.min()) / (S_db.max() - S_db.min())\n",
    "            elif method == \"zscore\":\n",
    "                mean = np.mean(S_db)\n",
    "                std = np.std(S_db)\n",
    "                return (S_db - mean) / std\n",
    "        else:\n",
    "            if method == \"minmax\":\n",
    "                return (S_db - stats[\"min\"]) / (stats[\"max\"] - stats[\"min\"])\n",
    "            elif method == \"zscore\":\n",
    "                return (S_db - stats[\"mean\"]) / stats[\"std\"]\n",
    "\n",
    "    def _pad_or_crop(S: np.ndarray, target_len: int):\n",
    "        current_len = S.shape[1]\n",
    "        if current_len < target_len:\n",
    "            pad_width = target_len - current_len\n",
    "            return np.pad(S, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            return S[:, :target_len]\n",
    "    \n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    S_norm = _normalize(S_db, method=normalization, scope=normalize_scope, stats=global_stats)\n",
    "    S_fixed = _pad_or_crop(S_norm, target_len=target_length)\n",
    "\n",
    "    return S_fixed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- pipeline ----------------------- #\n",
    "def pipeline(rename: bool = False, \n",
    "             limit: Union[int, None] = None,\n",
    "             clean_audio_params: dict = None,\n",
    "             save_comparisons: bool = False,\n",
    "             save_path: str = \"processed_dataset.parquet\") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Pipeline to run all preprocessing functions with timing and optional audio cleaning.\n",
    "    Only supports saving to .parquet (not CSV) to handle arrays properly.\n",
    "    \"\"\"\n",
    "    print(\"🚀 Starting preprocessing pipeline...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    if rename:\n",
    "        t0 = time.time()\n",
    "        rename_audio_files(\n",
    "            csv_path=ORG_CSV_PATH,\n",
    "            audio_dir=AUDIO_DIR,\n",
    "        )\n",
    "        print(f\"📝 rename_audio_files completed in {time.time() - t0:.2f} seconds\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    df = load_audio_metadata(\n",
    "        csv_path=RENAME_CSV_PATH,\n",
    "        audio_dir=AUDIO_DIR,\n",
    "        limit=limit,\n",
    "        clean_audio_params=clean_audio_params,\n",
    "        save_comparisons=save_comparisons\n",
    "    )\n",
    "    print(f\"⏳ load_audio_metadata completed in {time.time() - t0:.2f} seconds\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    stats = compute_or_load_global_stats(df[\"Audio\"].to_numpy(), sr=SAMPLE_RATE)\n",
    "    print(f\"🧮 compute_or_load_global_stats completed in {time.time() - t0:.2f} seconds\")\n",
    "    \n",
    "    print(\"\\n📈 Computed Statistics:\")\n",
    "    for k, v in stats.items(): \n",
    "        print(f\"  {k}: {v}\")\n",
    "    print()\n",
    "\n",
    "    t0 = time.time()\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"Audio\").map_elements(lambda y: audio_to_spectrogram(\n",
    "            y=np.array(y),\n",
    "            sr=SAMPLE_RATE,\n",
    "            normalization='zscore',\n",
    "            normalize_scope='global',\n",
    "            global_stats=stats\n",
    "        ), return_dtype=pl.Object).alias(\"Spectrogram\")\n",
    "    ])\n",
    "    print(f\"🔊 Spectrogram generation completed in {time.time() - t0:.2f} seconds\")\n",
    "    \n",
    "    print(f\"🏁 Full pipeline completed in {time.time() - start:.2f} seconds\\n\")\n",
    "    print(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commented out so pipeline doesn't start accidentally\n",
    "\n",
    "__Will__ blow up computer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_clean_params = {\n",
    "    'denoise': True,\n",
    "    'remove_silence': True,\n",
    "    'normalize': True,\n",
    "    'min_silence_duration': 0.3,\n",
    "    'silence_threshold': -40\n",
    "}\n",
    "\n",
    "df = pipeline(\n",
    "    rename=False, \n",
    "    limit=None,\n",
    "    clean_audio_params=custom_clean_params,\n",
    "    save_comparisons=False\n",
    ")\n",
    "\n",
    "Save DataFrame as Pickl\n",
    "df = df.with_columns([\n",
    "    pl.col(\"Audio\").map_elements(lambda y: np.array(y, dtype=np.float32).tolist(), return_dtype=pl.List(pl.Float32)),\n",
    "    pl.col(\"Spectrogram\").map_elements(lambda s: np.array(s, dtype=np.float32).tolist(), return_dtype=pl.List(pl.List(pl.Float32)))\n",
    "])\n",
    "with open(\"processed_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in data from cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle(path: str) -> pl.DataFrame:\n",
    "    with open(path, \"rb\") as f:\n",
    "        df = pickle.load(f)\n",
    "    return df\n",
    "\n",
    "df = open_pickle(\"./processed_data.pkl\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unique_label_spectrograms_grid(df, n_rows=4, n_cols=6):\n",
    "    unique_labels = df.select(\"Label\").unique().to_series().to_list()\n",
    "    total_plots = n_rows * n_cols\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 3))\n",
    "    axs = axs.flatten()\n",
    "    fig.suptitle(\"Unique Label Spectogram\", fontsize=30)\n",
    "\n",
    "    for idx, label in enumerate(unique_labels):\n",
    "        ax = axs[idx]\n",
    "\n",
    "        # Get the first spectrogram for this label\n",
    "        row = df.filter(pl.col(\"Label\") == label).row(0)\n",
    "        spectrogram = row[df.columns.index(\"Spectrogram\")]\n",
    "        spectrogram_np = np.array(spectrogram, dtype=np.float32)\n",
    "\n",
    "        if spectrogram_np.ndim == 2:\n",
    "            im = ax.imshow(spectrogram_np, aspect=\"auto\", origin=\"lower\", cmap=\"viridis\")\n",
    "            ax.set_title(label.upper(), fontsize=18)\n",
    "            ax.set_xlabel(\"Time\")\n",
    "            ax.set_ylabel(\"Freq\")\n",
    "        else:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    # Hide any unused axes\n",
    "    for j in range(len(unique_labels), len(axs)):\n",
    "        axs[j].axis(\"off\")\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrograms of Unique Label Groups\n",
    "\n",
    "This grid displays one **Mel spectrogram** for each unique vocalization label in the dataset. Each spectrogram represents a **single audio sample** randomly selected from that label group.\n",
    "\n",
    "#### Why Spectrograms?\n",
    "A spectrogram is a time-frequency visualization of sound. It shows how energy (brightness) is distributed across frequency bins (y-axis) over time (x-axis). Brighter regions indicate more intensity at that frequency and time.\n",
    "\n",
    "#### Why Do Some Spectrograms Cut Off or Show Flat Color?\n",
    "You may notice that many spectrograms appear to **suddenly turn into a solid blue color** after a certain point. This occurs because:\n",
    "\n",
    "- All spectrograms have been **padded or cropped to a fixed width** (`target_length`), ensuring uniform input size for modeling.\n",
    "- When the original audio sample is **shorter than the target time length**, the remaining time frames are filled with **zeros** — resulting in that flat, dark blue region on the right.\n",
    "- This is done to make all inputs the same shape for consistent processing and modeling (e.g., embeddings or CNNs).\n",
    "\n",
    "---\n",
    "\n",
    "These spectrograms give an intuitive view of the **acoustic patterns** present in each vocalization type — for example:\n",
    "- \"YES\" shows low-frequency harmonics,\n",
    "- \"FRUSTRATED\" is noisier and denser,\n",
    "- \"SELF-TALK\" often contains repeating patterns,\n",
    "- \"GLEE\" and \"DELIGHTED\" appear more tonal or melodic.\n",
    "\n",
    "This kind of visualization helps validate that **distinct spectral features** exist across labels, supporting downstream classification or clustering tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unique_label_spectrograms_grid(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction & Hypothesis Testing\n",
    "\n",
    "In this section, we extract acoustic features from vocalizations and statistically evaluate whether they differ significantly across expression labels. These tests aim to determine if vocal cues such as **pitch variability** and **spectral shape** (MFCCs) carry meaningful information that can distinguish between intents like `\"yes\"` and `\"no\"`.\n",
    "\n",
    "---\n",
    "\n",
    "### Tests Conducted:\n",
    "1. **Pitch Variability** – Mann-Whitney U test on pitch standard deviation across samples.\n",
    "2. **MFCC Differences** – Mann-Whitney U test on mean MFCC coefficients (1–3).\n",
    "3. _[Optional future test: e.g., energy, duration, zero-crossing rate, etc.]_\n",
    "\n",
    "---\n",
    "\n",
    "### Results:\n",
    "\n",
    "Our statistical tests revealed **significant acoustic differences** between `\"yes\"` and `\"no\"` vocalizations:\n",
    "\n",
    "- **Pitch Variability**:\n",
    "  - \"No\" vocalizations showed **much higher pitch variability** (std = 119.13) compared to \"Yes\" (std = 22.46).\n",
    "  - Mann-Whitney U test confirmed this with **p < 0.001** and a large effect size (**Cohen’s d = -2.38**).\n",
    "\n",
    "- **MFCCs (Spectral Shape)**:\n",
    "  - Significant differences were found in **MFCC-1** and **MFCC-3** (both **p < 0.001**, Cohen’s d > 1.6), indicating strong differences in **spectral slope** and **fine spectral variation**.\n",
    "  - **MFCC-2** showed **no significant difference**, suggesting similar mid-frequency emphasis in both groups.\n",
    "\n",
    "These findings suggest that both **pitch dynamics** and **spectral shape** are promising features for distinguishing vocal intent in non-verbal utterances for the model development phase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Pitch Variability Differences between \"Yes\" and \"No\" Vocalizations (Mann-Whitney U Test)\n",
    "\n",
    "This test evaluates whether there are statistically significant differences in **pitch variability** between vocalizations labeled as `\"yes\"` and `\"no\"`. Pitch variability is measured as the **standard deviation of estimated pitch (f₀)** across time for each audio sample. This metric reflects how much the speaker's pitch varies within a single utterance — often tied to emotional expressiveness or vocal intent.\n",
    "\n",
    "---\n",
    "\n",
    "#### What is Pitch Variability?\n",
    "\n",
    "- Calculated using **Librosa's PYIN algorithm**, which estimates fundamental frequency (f₀) for voiced segments of an audio signal.\n",
    "- We then compute the **standard deviation** of those f₀ values per sample.\n",
    "- A **higher pitch std** generally means more variation in tone, while a lower std suggests more monotonic vocalization.\n",
    "\n",
    "#### Test Setup\n",
    "\n",
    "- **Statistic**: Mann-Whitney U test (non-parametric)\n",
    "- **Effect Size**: Cohen’s *d*\n",
    "- **Input Feature**: Standard deviation of pitch per sample\n",
    "- **Groups Compared**: `\"yes\"` vs `\"no\"` vocalizations\n",
    "- **Sample Size**: 100 samples for \"yes\", 12 samples for \"no\"\n",
    "\n",
    "#### Group Means & Standard Deviations\n",
    "\n",
    "| Label      | Pitch Std (Mean ± Std) |\n",
    "|------------|------------------------|\n",
    "| **Yes**    | 22.46 ± 21.78          |\n",
    "| **No**     | 119.13 ± 110.34        |\n",
    "\n",
    "#### Statistical Results Summary\n",
    "\n",
    "| Metric             | Value                         |\n",
    "|--------------------|-------------------------------|\n",
    "| **U Statistic**     | 247.0                         |\n",
    "| **p-value**         | 0.00091                       |\n",
    "| **Cohen’s d**       | -2.38                         |\n",
    "| **Mean Difference** | -96.67                        |\n",
    "| **Significant**     |   Yes                         |\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- The **\"no\"** vocalizations exhibit **dramatically higher pitch variability** than \"yes\" samples — almost **5× higher on average**.\n",
    "- The test yields a **very low p-value (< 0.001)** and a **large negative effect size (Cohen’s d = -2.38)**, indicating a strong and statistically significant difference.\n",
    "- This suggests that **pitch dynamics** could be a powerful feature in differentiating certain types of vocal intent, especially when classifying expressive vs. flat responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_pitch_extraction(audio_list: List,\n",
    "                           max_samples_per_batch: int=50,\n",
    "                           sr: int=16000) -> List[float]:\n",
    "    # Randomly sample if batch is too large\n",
    "    if len(audio_list) > max_samples_per_batch:\n",
    "        sample_indices = np.random.choice(len(audio_list), max_samples_per_batch, replace=False)\n",
    "        audio_list = [audio_list[i] for i in sample_indices]\n",
    "    \n",
    "    pitch_stds = []\n",
    "    for audio_array in audio_list:\n",
    "        try:\n",
    "            audio_array = np.asarray(audio_array, dtype=np.float64)\n",
    "            \n",
    "            # Extract pitch using PYIN\n",
    "            f0, voiced_flag, _ = librosa.pyin(\n",
    "                audio_array, \n",
    "                fmin=librosa.note_to_hz('C2'),\n",
    "                fmax=librosa.note_to_hz('C7'),\n",
    "                sr=sr\n",
    "            )\n",
    "            \n",
    "            # Filter for voiced segments\n",
    "            f0_voiced = f0[voiced_flag]\n",
    "            \n",
    "            # Calculate pitch std, handle empty case\n",
    "            pitch_std = float(np.std(f0_voiced)) if len(f0_voiced) > 0 else 0.0\n",
    "            pitch_stds.append(pitch_std)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Pitch extraction error: {e}\")\n",
    "            pitch_stds.append(0.0)\n",
    "    \n",
    "    return pitch_stds\n",
    "\n",
    "def pitch_variability_test(df: pl.DataFrame,\n",
    "                           max_batch_size: int=50,\n",
    "                           target_labels: List[str]=['frustrated', 'delighted']) -> Dict[str, float]:\n",
    "    # Group audio by label\n",
    "    label_audio_groups = {}\n",
    "    for label in target_labels:\n",
    "        # Extract audio for each label\n",
    "        label_audio_groups[label] = df.filter(pl.col(\"Label\") == label)[\"Audio\"].to_list()\n",
    "    \n",
    "    # Batch pitch extraction\n",
    "    label_pitch_stds = {}\n",
    "    for label, audio_list in label_audio_groups.items():\n",
    "        label_pitch_stds[label] = batch_pitch_extraction(audio_list=audio_list, max_samples_per_batch=max_batch_size)\n",
    "        \n",
    "        # Print basic stats\n",
    "        pitch_array = np.array(label_pitch_stds[label])\n",
    "        print(f\"{label} samples: {len(pitch_array)}\")\n",
    "        print(f\"  Mean pitch std: {np.mean(pitch_array):.4f}\")\n",
    "        print(f\"  Std of pitch std: {np.std(pitch_array):.4f}\")\n",
    "    \n",
    "    # Perform statistical tests\n",
    "    label1_data = label_pitch_stds[target_labels[0]]\n",
    "    label2_data = label_pitch_stds[target_labels[1]]\n",
    "    \n",
    "    # Mann-Whitney U Test\n",
    "    u_statistic, p_value = scipy.stats.mannwhitneyu(\n",
    "        label1_data, \n",
    "        label2_data, \n",
    "        alternative='two-sided'\n",
    "    )\n",
    "    \n",
    "    # Effect size calculation (Cohen's d)\n",
    "    mean1, std1 = np.mean(label1_data), np.std(label1_data)\n",
    "    mean2, std2 = np.mean(label2_data), np.std(label2_data)\n",
    "    \n",
    "    # Pooled standard deviation\n",
    "    pooled_std = np.sqrt(((len(label1_data) - 1) * std1**2 + \n",
    "                          (len(label2_data) - 1) * std2**2) / \n",
    "                         (len(label1_data) + len(label2_data) - 2))\n",
    "    \n",
    "    # Cohen's d\n",
    "    cohens_d = (mean1 - mean2) / pooled_std\n",
    "    \n",
    "    # Prepare results\n",
    "    results = {\n",
    "        'Mann-Whitney U Statistic': u_statistic,\n",
    "        'p-value': p_value,\n",
    "        'Cohen\\'s d': cohens_d,\n",
    "        'Mean Difference': mean1 - mean2,\n",
    "        'Significant': p_value < 0.05\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n=== Hypothesis Test Results ===\")\n",
    "    for key, value in results.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectogram plotting functions to compare labels \n",
    "def plot_spectrogram_comparison(df, label1=\"yes\", label2=\"no\", sr=SAMPLE_RATE, n_examples=2):\n",
    "    fig, axes = plt.subplots(n_examples, 2, figsize=(12, 4 * n_examples))\n",
    "    label_map = {0: label1, 1: label2}\n",
    "\n",
    "    for i, label in enumerate([label1, label2]):\n",
    "        examples = df.filter(pl.col(\"Label\") == label).head(n_examples).iter_rows(named=True)\n",
    "        for j, row in enumerate(examples):\n",
    "            y = np.array(row[\"Audio\"])\n",
    "            S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "            S_db = librosa.power_to_db(S, ref=np.max)\n",
    "            ax = axes[j, i] if n_examples > 1 else axes[i]\n",
    "            librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='mel', ax=ax)\n",
    "            ax.set_title(f\"{label_map[i].upper()} Sample #{j+1}\")\n",
    "            ax.set_xlabel(\"\")\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "    plt.suptitle(\"Mel Spectrogram Comparison: YES vs NO\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "results = pitch_variability_test(df=df, max_batch_size=100, target_labels=[\"yes\", \"no\"])\n",
    "print(f\"\\n🎶 Pitch Variability Test completed in {time.time() - t0:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram_comparison(df, label1=\"yes\", label2=\"no\", sr=SAMPLE_RATE, n_examples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: MFCC Mean Differences between \"Yes\" and \"No\" Vocalizations (Mann-Whitney U Test)\n",
    "\n",
    "This test evaluates whether there are statistically significant differences in **spectral shape** between the vocalizations labeled as `\"yes\"` and `\"no\"`, using the **mean values of the first three MFCCs**.\n",
    "\n",
    "---\n",
    "\n",
    "#### What are MFCCs?\n",
    "\n",
    "- **MFCC-1**: Captures the overall **spectral slope** — indicates the energy balance between low and high frequencies.\n",
    "- **MFCC-2**: Captures the **curvature** of the spectral envelope — flat vs. peaked energy in the mid frequencies.\n",
    "- **MFCC-3**: Represents **fine-grained variation** — subtle changes or \"ripples\" in the spectral shape.\n",
    "- Higher-order MFCCs (4, 5, …) capture increasingly localized detail and high-frequency texture.\n",
    "\n",
    "---\n",
    "\n",
    "#### Test Setup\n",
    "\n",
    "- **Statistic**: Mann-Whitney U test\n",
    "- **Effect Size**: Cohen’s *d*\n",
    "- **Input Features**: Mean of MFCC-1 to MFCC-3 per sample\n",
    "- **Groups Compared**: `\"yes\"` vs `\"no\"` vocalizations\n",
    "- **Sample Size**: 50 samples per label\n",
    "\n",
    "---\n",
    "\n",
    "#### Why This Matters\n",
    "\n",
    "If MFCC means differ significantly between groups, it suggests that **spectral characteristics** of the vocalizations carry **discriminative information**. This can help differentiate types of vocal intent, even in non-verbal speech.\n",
    "\n",
    "---\n",
    "\n",
    "#### Results\n",
    "\n",
    "__Group Means & Standard Deviations__\n",
    "\n",
    "| Label | MFCC-1 Mean ± Std | MFCC-2 Mean ± Std | MFCC-3 Mean ± Std |\n",
    "|-------|-------------------|-------------------|-------------------|\n",
    "| **Yes** | -325.40 ± 35.08 | 125.82 ± 20.04 | 25.99 ± 16.56 |\n",
    "| **No**  | -255.81 ± 48.42 | 128.74 ± 29.64 | -1.40 ± 20.49 |\n",
    "\n",
    "\n",
    "__Statistical Results Summary__\n",
    "\n",
    "| MFCC      | U Statistic | p-value        | Cohen’s *d* | Mean Diff | Significant |\n",
    "|-----------|-------------|----------------|-------------|-----------|-------------|\n",
    "| **MFCC-1** | 148.0       | 2.16e-05      | -1.90       | -69.59    |  Yes        |\n",
    "| **MFCC-2** | 571.0       | 0.7886        | -0.14       | -2.92     |  No         |\n",
    "| **MFCC-3** | 1010.0      | 0.00012       | +1.61       | +27.39    |  Yes        |\n",
    "\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **MFCC-1** and **MFCC-3** show statistically significant and **large** differences between \"yes\" and \"no\" samples (Cohen’s *d* > 1.5).\n",
    "- **MFCC-2** does not differ significantly between the two groups.\n",
    "- These results indicate that **low and mid-frequency spectral properties** (slope and variation) carry meaningful differences between vocalizations, while overall mid-frequency curvature does not.\n",
    "\n",
    "*This suggests that MFCC-1 and MFCC-3 may be useful features for classifying or clustering intent in non-verbal vocalizations.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_mfcc_extraction(audio_list: List,\n",
    "                          max_samples_per_batch: int=50,\n",
    "                          sr: int=SAMPLE_RATE,\n",
    "                          n_coeffs: int=3) -> List[float]:\n",
    "    if len(audio_list) > max_samples_per_batch:\n",
    "        sample_indices = np.random.choice(len(audio_list), max_samples_per_batch, replace=False)\n",
    "        audio_list = [audio_list[i] for i in sample_indices]\n",
    "    \n",
    "    mfcc_means = []\n",
    "    for audio_array in audio_list:\n",
    "        try:\n",
    "            audio_array = np.asarray(audio_array, dtype=np.float32)\n",
    "            mfccs = librosa.feature.mfcc(y=audio_array, sr=sr, n_mfcc=n_coeffs)\n",
    "            mfcc_mean = np.mean(mfccs, axis=1)\n",
    "            mfcc_means.append(mfcc_mean)\n",
    "        except Exception as e:\n",
    "            print(f\"MFCC extraction error: {e}\")\n",
    "            mfcc_means.append(np.zeros(n_coeffs))\n",
    "    \n",
    "    return mfcc_means\n",
    "\n",
    "\n",
    "def mfcc_significance_test(df, max_batch_size=50, target_labels=[\"frustrated\", \"delighted\"], n_coeffs=3):\n",
    "    label_audio_groups = {}\n",
    "    for label in target_labels:\n",
    "        label_audio_groups[label] = df.filter(pl.col(\"Label\") == label)[\"Audio\"].to_list()\n",
    "    \n",
    "    label_mfcc_means = {}\n",
    "    for label, audio_list in label_audio_groups.items():\n",
    "        label_mfcc_means[label] = batch_mfcc_extraction(\n",
    "            audio_list,\n",
    "            max_samples_per_batch=max_batch_size,\n",
    "            n_coeffs=n_coeffs,\n",
    "            sr=SAMPLE_RATE\n",
    "        )\n",
    "        mfcc_array = np.array(label_mfcc_means[label])\n",
    "        print(f\"{label} samples: {len(mfcc_array)}\")\n",
    "        \n",
    "        for i in range(n_coeffs):\n",
    "            print(f\"  MFCC-{i+1} Mean: {np.mean(mfcc_array[:, i]):.4f}, Std: {np.std(mfcc_array[:, i]):.4f}\")\n",
    "\n",
    "    results = {}\n",
    "    for i in range(n_coeffs):\n",
    "        data1 = [x[i] for x in label_mfcc_means[target_labels[0]]]\n",
    "        data2 = [x[i] for x in label_mfcc_means[target_labels[1]]]\n",
    "\n",
    "        u_statistic, p_value = scipy.stats.mannwhitneyu(data1, data2, alternative='two-sided')\n",
    "        mean1, std1 = np.mean(data1), np.std(data1)\n",
    "        mean2, std2 = np.mean(data2), np.std(data2)\n",
    "\n",
    "        pooled_std = np.sqrt(((len(data1) - 1) * std1**2 + (len(data2) - 1) * std2**2) /\n",
    "                             (len(data1) + len(data2) - 2))\n",
    "        cohens_d = (mean1 - mean2) / pooled_std\n",
    "\n",
    "        results[f\"MFCC-{i+1}\"] = {\n",
    "            'U Statistic': u_statistic,\n",
    "            'p-value': p_value,\n",
    "            'Cohen\\'s d': cohens_d,\n",
    "            'Mean Difference': mean1 - mean2,\n",
    "            'Significant': p_value < 0.05\n",
    "        }\n",
    "\n",
    "    print(\"\\n=== MFCC Significance Test Results ===\")\n",
    "    for k, v in results.items():\n",
    "        print(f\"\\n{k}\")\n",
    "        for stat, val in v.items():\n",
    "            print(f\"  {stat}: {val}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box whisker and heatmap to visualize distribution of MFCC (compare means)\n",
    "def box_and_heat_mfcc_comparison(df, labels=[\"yes\", \"no\"], sr=SAMPLE_RATE, n_mfcc=3):\n",
    "    # Step 1: Prepare data\n",
    "    data = []\n",
    "    mfcc_data = {label: [] for label in labels}\n",
    "\n",
    "    for label in labels:\n",
    "        for row in df.filter(pl.col(\"Label\") == label).iter_rows(named=True):\n",
    "            y = np.array(row[\"Audio\"])\n",
    "            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "            mfcc_mean = np.mean(mfccs, axis=1)\n",
    "\n",
    "            # For boxplot\n",
    "            for i in range(n_mfcc):\n",
    "                data.append({\n",
    "                    \"MFCC\": f\"MFCC-{i+1}\",\n",
    "                    \"Value\": mfcc_mean[i],\n",
    "                    \"Label\": label\n",
    "                })\n",
    "\n",
    "            # For heatmap\n",
    "            mfcc_data[label].append(mfcc_mean)\n",
    "\n",
    "    # DataFrames\n",
    "    df_plot = pd.DataFrame(data)\n",
    "    heat_data = []\n",
    "    for label in labels:\n",
    "        means = np.mean(np.stack(mfcc_data[label]), axis=0)\n",
    "        row = [means[i] for i in range(n_mfcc)]\n",
    "        heat_data.append(row)\n",
    "    df_heat = pd.DataFrame(heat_data, columns=[f\"MFCC-{i+1}\" for i in range(n_mfcc)], index=[label.upper() for label in labels])\n",
    "\n",
    "    # Step 2: Plot side-by-side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # Boxplot\n",
    "    sns.boxplot(data=df_plot, x=\"MFCC\", y=\"Value\", hue=\"Label\", ax=axes[0])\n",
    "    axes[0].set_title(\"MFCC Distribution (Boxplot)\")\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Heatmap\n",
    "    sns.heatmap(df_heat, annot=True, fmt=\".1f\", cmap=\"viridis\", ax=axes[1])\n",
    "    axes[1].set_title(\"MFCC Mean Comparison (Heatmap)\")\n",
    "    axes[1].set_ylabel(\"Label\")\n",
    "    axes[1].set_xlabel(\"MFCC Coefficient\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "results = mfcc_significance_test(df, max_batch_size=100, target_labels=[\"yes\", \"no\"], n_coeffs=3)\n",
    "print(f\"\\n🎛️ MFCC Significance Test completed in {time.time() - t0:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_and_heat_mfcc_comparison(df, labels=[\"yes\", \"no\"], n_mfcc=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Spectral Entropy Differences Across Vocalization Labels (ANOVA & T-Tests)\n",
    "\n",
    "This analysis investigates whether there are statistically significant differences in **spectral entropy** between different vocalization labels (`\"dysregulated\"`, `\"hunger\"`, `\"delighted\"`).\n",
    "\n",
    "---\n",
    "\n",
    "#### What is Spectral Entropy?\n",
    "\n",
    "Spectral entropy measures the **disorder** or **randomness** in an audio signal's frequency distribution. A higher entropy indicates a more uniform spectral distribution, while lower entropy suggests a more structured or tonal signal.\n",
    "\n",
    "---\n",
    "\n",
    "#### Test Setup\n",
    "\n",
    "- **Statistic**: One-way ANOVA & Pairwise T-tests\n",
    "- **Effect Size**: Cohen’s *d* (for pairwise comparisons)\n",
    "- **Input Feature**: Spectral entropy computed from short-time Fourier transform (STFT)\n",
    "- **Groups Compared**: `\"dysregulated\"`, `\"hunger\"`, `\"delighted\"`\n",
    "- **Sample Size**: Maximum of 100 samples per label\n",
    "\n",
    "---\n",
    "\n",
    "#### Why This Matters\n",
    "\n",
    "If spectral entropy differs significantly between groups, it suggests that **vocalizations exhibit distinct spectral characteristics**. This could help in distinguishing different emotional states based on entropy patterns.\n",
    "\n",
    "---\n",
    "\n",
    "#### Results\n",
    "\n",
    "__ANOVA Results__\n",
    "\n",
    "| Test | F-Statistic | p-value | Significant |\n",
    "|------|------------|---------|-------------|\n",
    "| **Spectral Entropy** | 5.63 | 0.0024 | Yes |\n",
    "\n",
    "A significant ANOVA result suggests that at least one group has a different spectral entropy distribution.\n",
    "\n",
    "---\n",
    "\n",
    "__Pairwise T-Test Summary__\n",
    "\n",
    "| Comparison | T-Statistic | p-value | Cohen’s *d* | Significant |\n",
    "|------------|------------|---------|-------------|-------------|\n",
    "| **Dysregulated vs Hunger** | -2.94 | 0.0041 | -0.78 | Yes |\n",
    "| **Dysregulated vs Delighted** | 1.15 | 0.2512 | 0.31 | No |\n",
    "| **Hunger vs Delighted** | 3.22 | 0.0015 | 0.86 | Yes |\n",
    "\n",
    "*Significance threshold adjusted using Bonferroni correction.*\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **Dysregulated vs Hunger**: Significant difference in spectral entropy, suggesting that these vocalizations differ in spectral complexity.\n",
    "- **Hunger vs Delighted**: Significant difference, indicating distinct spectral patterns between these groups.\n",
    "- **Dysregulated vs Delighted**: No significant difference, suggesting similar spectral entropy distributions.\n",
    "\n",
    "These findings imply that spectral entropy is a meaningful feature for distinguishing some vocalization states but may not differentiate all categories equally.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_entropy(audio_list):\n",
    "    \"\"\"Calculate spectral entropy for each audio sample.\"\"\"\n",
    "    entropy_values = []\n",
    "\n",
    "    for audio_array in audio_list:\n",
    "        audio_array = np.asarray(audio_array, dtype=np.float32)\n",
    "        S = np.abs(librosa.stft(audio_array))\n",
    "        S /= np.sum(S, axis=0)  # Normalize by total energy per frame\n",
    "        spectral_entropy = -np.sum(S * np.log(S + 1e-10), axis=0)\n",
    "        entropy_values.append(float(np.mean(spectral_entropy)))\n",
    "\n",
    "    return entropy_values\n",
    "\n",
    "\n",
    "def spectral_entropy_anova_test(df, target_labels=[\"dysregulated\", \"hunger\", \"delighted\"], max_samples_per_label=50):\n",
    "    \"\"\"Perform ANOVA on spectral entropy differences.\"\"\"\n",
    "    label_audio_groups = {label: df.filter(pl.col(\"Label\") == label)[\"Audio\"].to_list() for label in target_labels}\n",
    "    label_entropy_means = {label: compute_spectral_entropy(audio_list[:max_samples_per_label])\n",
    "                            for label, audio_list in label_audio_groups.items()}\n",
    "    data = [label_entropy_means[label] for label in target_labels]\n",
    "\n",
    "    # One-way ANOVA test\n",
    "    f_statistic, p_value = scipy.stats.f_oneway(*data)\n",
    "\n",
    "    results = {\n",
    "        'ANOVA F-Statistic': f_statistic,\n",
    "        'p-value': p_value,\n",
    "        'Significant': p_value < 0.05\n",
    "    }\n",
    "\n",
    "    print(\"\\n=== Spectral Entropy ANOVA Test Results ===\")\n",
    "    for key, value in results.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "results = spectral_entropy_anova_test(df, target_labels=[\"dysregulated\", \"hunger\", \"delighted\"], max_samples_per_label=100)\n",
    "print(f\"\\nSpectral Entropy ANOVA Test completed in {time.time() - t0:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_entropy(y):\n",
    "    # Compute power spectral density\n",
    "    S = np.abs(librosa.stft(y))**2\n",
    "    \n",
    "    # Normalize each frame to create a probability distribution\n",
    "    S_norm = S / (np.sum(S, axis=0) + 1e-10)\n",
    "    \n",
    "    # Compute Shannon entropy using log base 2 (information-theoretic interpretation)\n",
    "    spectral_entropy = -np.sum(S_norm * np.log2(S_norm + 1e-10), axis=0)\n",
    "    \n",
    "    # Normalize by maximum possible entropy for the given frequency bins\n",
    "    max_entropy = np.log2(S.shape[0])  # log2(n_bins)\n",
    "    normalized_entropy = spectral_entropy / max_entropy\n",
    "    \n",
    "    return float(np.mean(normalized_entropy))\n",
    "\n",
    "\n",
    "def pairwise_t_test(df, target_labels, feature=\"Spectral Entropy\"):\n",
    "    label_data = {label: df.filter(pl.col(\"Label\") == label)[feature].to_list() for label in target_labels}\n",
    "\n",
    "    results = {}\n",
    "    alpha = 0.05 / (len(target_labels) * (len(target_labels) - 1) / 2)\n",
    "\n",
    "    for i in range(len(target_labels)):\n",
    "        for j in range(i + 1, len(target_labels)):\n",
    "            label1, label2 = target_labels[i], target_labels[j]\n",
    "            data1, data2 = label_data[label1], label_data[label2]\n",
    "\n",
    "            t_statistic, p_value = scipy.stats.ttest_ind(data1, data2, equal_var=False)\n",
    "\n",
    "            results[f\"{label1} vs {label2}\"] = {\n",
    "                \"T-Statistic\": t_statistic,\n",
    "                \"P-Value\": p_value,\n",
    "                \"Significant\": p_value < alpha\n",
    "            }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def format_t_test_results(results_dict):\n",
    "    df_results = pd.DataFrame.from_dict(results_dict, orient=\"index\")\n",
    "    df_results.rename(columns={\"T-Statistic\": \"T-Statistic\", \"P-Value\": \"P-Value\", \"Significant\": \"Significant\"}, inplace=True)\n",
    "    \n",
    "    # Apply scientific notation for small p-values\n",
    "    df_results[\"P-Value\"] = df_results[\"P-Value\"].apply(lambda x: f\"{x:.15e}\" if x < 1e-5 else f\"{x:.15f}\")\n",
    "\n",
    "    print(\"\\n=== Pairwise T-Test Results ===\\n\")\n",
    "    print(df_results.to_string(index=True))\n",
    "\n",
    "\n",
    "def plot_spectral_entropy_comparison(df, target_labels, feature=\"Spectral Entropy\"):\n",
    "    \"\"\"Generate a boxplot for spectral entropy distributions across groups.\"\"\"\n",
    "    data = [(label, value) for label in target_labels for value in df.filter(pl.col(\"Label\") == label)[feature].to_list()]\n",
    "    df_plot = pd.DataFrame(data, columns=[\"Label\", feature])\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x=\"Label\", y=feature, data=df_plot, hue=\"Label\", palette=\"Set2\", legend=False)\n",
    "    plt.title(\"Spectral Entropy Comparison Across Labels\")\n",
    "    plt.ylabel(\"Spectral Entropy\")\n",
    "    plt.xlabel(\"Label\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Pairwise T-Test Results ===\n",
      "\n",
      "                            GroupsT-Statistic                P-Value  Significant\n",
      "glee vs happy                       -2.511873      0.032841722959323        False\n",
      "glee vs frustrated                  -1.751809      0.122592899384257        False\n",
      "glee vs hunger                      -5.155747      0.000534773625564         True\n",
      "glee vs dysregulated                -0.328050      0.752223579422642        False\n",
      "happy vs frustrated                  2.380167      0.020164900369932        False\n",
      "happy vs hunger                     -4.378267      0.010199798714912        False\n",
      "happy vs dysregulated                5.941458  9.363763555221191e-08         True\n",
      "frustrated vs hunger                -5.839670      0.009419767330046        False\n",
      "frustrated vs dysregulated           9.791760  5.256165567986213e-22         True\n",
      "hunger vs dysregulated               7.471177      0.004383527852241         True\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_test_results = pairwise_t_test(df, target_labels=[\"glee\", \"happy\", \"frustrated\", \"hunger\", \"dysregulated\"], feature=\"Spectral Entropy\")\n",
    "format_t_test_results(t_test_results)\n",
    "plot_spectral_entropy_comparison(df, target_labels=[\"glee\", \"happy\", \"frustrated\", \"hunger\", \"dysregulated\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
