{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 2 Notebook\n",
    "\n",
    "__TODO__:\n",
    "- fill this cell in with info, results, insights from our EDA \n",
    "- preprocess: create preprocessing pipeline, store all code into script, then run script to preprocess all data and store into pickle\n",
    "- analysis: need \"3 hypothesis tests\" to validate hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- imports ------------- #\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import polars as pl\n",
    "from typing import Union, List, Dict\n",
    "import json\n",
    "import time\n",
    "\n",
    "# ------------ macros ------------ #\n",
    "SAMPLE_RATE = 16e3\n",
    "\n",
    "\n",
    "# ----------------------- preprocessing functions ----------------------- #\n",
    "def rename_audio_files(csv_path: str,\n",
    "                       audio_dir: str,\n",
    "                       output_csv: str = \"renamed_metadata.csv\") -> None:\n",
    "    \"\"\"\n",
    "    Renames audio files based on Participant and Label and saves new metadata.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the input metadata CSV.\n",
    "        audio_dir (str): Directory containing audio files.\n",
    "        output_csv (str): Filename for the output metadata CSV.\n",
    "    \"\"\"\n",
    "    df = pl.read_csv(csv_path)\n",
    "    renamed_files = []\n",
    "    file_counts = {}\n",
    "\n",
    "    for file in df.iter_rows(named=True):\n",
    "        org_name = file['Filename']\n",
    "        id = file['Participant']\n",
    "        label = file['Label']\n",
    "\n",
    "        key = (id, label)\n",
    "        file_counts[key] = file_counts.get(key, 0) + 1\n",
    "        index = file_counts[key]\n",
    "\n",
    "        new_name = f\"{id}_{label}_{index}.wav\"\n",
    "        old_path = os.path.join(audio_dir, org_name)\n",
    "        new_path = os.path.join(audio_dir, new_name)\n",
    "\n",
    "        os.rename(old_path, new_path)\n",
    "        renamed_files.append((new_name, id, label, index))\n",
    "\n",
    "    renamed_df = pl.DataFrame(renamed_files, schema=[\"Filename\", \"ID\", \"Label\", \"Index\"], orient=\"row\")\n",
    "    output_path = os.path.join(audio_dir, output_csv)\n",
    "    renamed_df.write_csv(output_path)\n",
    "\n",
    "\n",
    "def load_audio_metadata(csv_path: str,\n",
    "                        audio_dir: str,\n",
    "                        limit: Union[int, None] = None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads audio files from directory and returns a DataFrame with waveform and metadata.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file containing data.\n",
    "        audio_dir (str): Directory where audio files are stored.\n",
    "        limit (int, optional): Number of rows to load. If None, loads all.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame with columns: Filename, Audio, ID, Label, Duration, Index\n",
    "    \"\"\"\n",
    "    df = pl.read_csv(csv_path)\n",
    "    if limit:\n",
    "        df = df.head(limit)\n",
    "\n",
    "    audio_data = []\n",
    "\n",
    "    for row in df.iter_rows(named=True):\n",
    "        file_name = row['Filename']\n",
    "        file_path = os.path.join(audio_dir, file_name)\n",
    "\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        duration = len(y) / sr\n",
    "\n",
    "        audio_data.append((\n",
    "            file_name,\n",
    "            y.tolist(),\n",
    "            row['ID'],\n",
    "            row['Label'],\n",
    "            duration,\n",
    "            row['Index']\n",
    "        ))\n",
    "\n",
    "    audio_df = pl.DataFrame(\n",
    "        audio_data,\n",
    "        schema=[\"Filename\", \"Audio\", \"ID\", \"Label\", \"Duration\", \"Index\"],\n",
    "        orient='row'\n",
    "    )\n",
    "\n",
    "    return audio_df\n",
    "\n",
    "\n",
    "def compute_or_load_global_stats(ys: List[np.ndarray],\n",
    "                                 sr: int,\n",
    "                                 n_mels: int = 128,\n",
    "                                 method: str = \"zscore\",\n",
    "                                 stats_file: str = \"global_stats.json\",\n",
    "                                 force_recompute: bool = False) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Computes or loads global normalization stats for Mel spectrograms.\n",
    "\n",
    "    Parameters:\n",
    "        ys (List[np.ndarray]): List of raw audio waveforms.\n",
    "        sr (int): Sample rate.\n",
    "        n_mels (int): Number of Mel bands.\n",
    "        method (str): 'zscore' or 'minmax'.\n",
    "        stats_file (str): Path to save/load stats JSON.\n",
    "        force_recompute (bool): If True, recomputes even if file exists.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: Stats dictionary (mean/std or min/max).\n",
    "    \"\"\"\n",
    "\n",
    "    if not force_recompute and os.path.exists(stats_file):\n",
    "        print(f\"ðŸ—‚ï¸ Loading global stats from {stats_file}\")\n",
    "        with open(stats_file, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    print(f\"ðŸ“Š Computing global stats with method '{method}'...\")\n",
    "    all_values = []\n",
    "\n",
    "    for y in ys:\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "        S_db = librosa.power_to_db(S, ref=np.max)\n",
    "        all_values.append(S_db.flatten())\n",
    "\n",
    "    all_values = np.concatenate(all_values)\n",
    "    stats = {}\n",
    "\n",
    "    if method == \"zscore\":\n",
    "        stats = {\n",
    "            \"mean\": float(np.mean(all_values)),\n",
    "            \"std\": float(np.std(all_values))\n",
    "        }\n",
    "    elif method == \"minmax\":\n",
    "        stats = {\n",
    "            \"min\": float(np.min(all_values)),\n",
    "            \"max\": float(np.max(all_values))\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Use 'zscore' or 'minmax'.\")\n",
    "\n",
    "    # Save stats to file\n",
    "    with open(stats_file, \"w\") as f:\n",
    "        json.dump(stats, f)\n",
    "        print(f\"ðŸ’¾ Saved global stats to {stats_file}\")\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "\n",
    "def audio_to_spectrogram(y: np.ndarray,\n",
    "                         sr: int,\n",
    "                         n_mels: int = 128,\n",
    "                         target_length: int = 128,\n",
    "                         normalization: str = \"minmax\",\n",
    "                         normalize_scope: str = \"sample\",  # \"sample\" or \"global\"\n",
    "                         global_stats: dict = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts a raw audio waveform into a normalized, fixed-size Mel spectrogram.\n",
    "\n",
    "    Parameters:\n",
    "        y (np.ndarray): Raw audio waveform.\n",
    "        sr (int): Sample rate of the audio.\n",
    "        n_mels (int): Number of Mel bands.\n",
    "        target_length (int): Number of time steps to pad/crop to.\n",
    "        normalization (str): 'minmax' or 'zscore'.\n",
    "        normalize_scope (str): 'sample' for per-sample normalization,\n",
    "                               'global' for dataset-wide using global_stats.\n",
    "        global_stats (dict): Required if normalize_scope='global'. Should contain\n",
    "                             'mean' and 'std' or 'min' and 'max'.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Mel spectrogram of shape (n_mels, target_length).\n",
    "    \"\"\"\n",
    "\n",
    "    def _normalize(S_db: np.ndarray, method: str, scope: str, stats: dict = None):\n",
    "        if scope == \"sample\":\n",
    "            if method == \"minmax\":\n",
    "                return (S_db - S_db.min()) / (S_db.max() - S_db.min())\n",
    "            elif method == \"zscore\":\n",
    "                mean = np.mean(S_db)\n",
    "                std = np.std(S_db)\n",
    "                return (S_db - mean) / std\n",
    "        elif scope == \"global\":\n",
    "            if stats is None:\n",
    "                raise ValueError(\"Global normalization requires global_stats.\")\n",
    "            if method == \"minmax\":\n",
    "                return (S_db - stats[\"min\"]) / (stats[\"max\"] - stats[\"min\"])\n",
    "            elif method == \"zscore\":\n",
    "                return (S_db - stats[\"mean\"]) / stats[\"std\"]\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported normalization scope. Use 'sample' or 'global'.\")\n",
    "\n",
    "    def _pad_or_crop(S: np.ndarray, target_len: int):\n",
    "        current_len = S.shape[1]\n",
    "        if current_len < target_len:\n",
    "            pad_width = target_len - current_len\n",
    "            return np.pad(S, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            return S[:, :target_len]\n",
    "\n",
    "    # Compute Mel spectrogram and convert to dB\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    # Normalize\n",
    "    S_norm = _normalize(S_db, method=normalization, scope=normalize_scope, stats=global_stats)\n",
    "\n",
    "    # Fix shape\n",
    "    S_fixed = _pad_or_crop(S_norm, target_len=target_length)\n",
    "\n",
    "    return S_fixed\n",
    "\n",
    "\n",
    "\n",
    "def pipeline(rename: bool=False, limit: Union[int, None] = None):\n",
    "    \"\"\"\n",
    "    Pipeline to run all preprocessing functions with timing.\n",
    "    \"\"\"\n",
    "    print(\"ðŸš€ Starting preprocessing pipeline...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    # Step 1: Rename files\n",
    "    if rename:\n",
    "        t0 = time.time()\n",
    "        rename_audio_files(\n",
    "            \"/Users/visheshnarayan/Documents/Code/School/CMSC320/cmsc320-final/ReCANVo/dataset_file_directory.csv\",\n",
    "            \"/Users/visheshnarayan/Documents/Code/School/CMSC320/cmsc320-final/ReCANVo/\"\n",
    "        )\n",
    "        print(f\"ðŸ“ rename_audio_files completed in {time.time() - t0:.2f} seconds\")\n",
    "\n",
    "    # Step 2: Load audio metadata\n",
    "    t0 = time.time()\n",
    "    df = load_audio_metadata(\n",
    "        csv_path=\"/Users/visheshnarayan/Documents/Code/School/CMSC320/cmsc320-final/ReCANVo/renamed_metadata.csv\",\n",
    "        audio_dir=\"/Users/visheshnarayan/Documents/Code/School/CMSC320/cmsc320-final/ReCANVo/\",\n",
    "        limit=limit\n",
    "    )\n",
    "    print(f\"â³ load_audio_metadata completed in {time.time() - t0:.2f} seconds\")\n",
    "\n",
    "    # Step 3: Compute or load global stats\n",
    "    t0 = time.time()\n",
    "    stats = compute_or_load_global_stats(df[\"Audio\"].to_numpy(), sr=SAMPLE_RATE)\n",
    "    print(f\"ðŸ§® compute_or_load_global_stats completed in {time.time() - t0:.2f} seconds\")\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ Computed Statistics:\")\n",
    "    for k, v in stats.items(): \n",
    "        print(f\"  {k}: {v}\")\n",
    "    print()\n",
    "\n",
    "    # Step 4: Compute spectrograms\n",
    "    t0 = time.time()\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"Audio\").map_elements(lambda y: audio_to_spectrogram(\n",
    "            y=np.array(y),\n",
    "            sr=SAMPLE_RATE,\n",
    "            normalization='zscore',\n",
    "            normalize_scope='global',\n",
    "            global_stats=stats\n",
    "        ), return_dtype=pl.Object).alias(\"Spectrogram\")\n",
    "    ])\n",
    "    print(f\"ðŸ”Š Spectrogram generation completed in {time.time() - t0:.2f} seconds\")\n",
    "\n",
    "    # Done\n",
    "    print(f\"\\nðŸ Full pipeline completed in {time.time() - start:.2f} seconds\\n\")\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting preprocessing pipeline...\n",
      "ðŸ“ rename_audio_files completed in 0.98 seconds\n",
      "â³ load_audio_metadata completed in 206.69 seconds\n",
      "ðŸ—‚ï¸ Loading global stats from global_stats.json\n",
      "ðŸ§® compute_or_load_global_stats completed in 0.15 seconds\n",
      "\n",
      "ðŸ“ˆ Computed Statistics:\n",
      "  mean: -55.975612227106474\n",
      "  std: 18.55726476893056\n",
      "\n",
      "ðŸ”Š Spectrogram generation completed in 26.33 seconds\n",
      "\n",
      "ðŸ Full pipeline completed in 234.17 seconds\n",
      "\n",
      "shape: (7_077, 7)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ Filename          â”† Audio        â”† ID  â”† Label             â”† Duration â”† Index â”† Spectrogram      â”‚\n",
      "â”‚ ---               â”† ---          â”† --- â”† ---               â”† ---      â”† ---   â”† ---              â”‚\n",
      "â”‚ str               â”† list[f64]    â”† str â”† str               â”† f64      â”† i64   â”† object           â”‚\n",
      "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ P01_dysregulation â”† [-0.146042,  â”† P01 â”† dysregulation-sic â”† 0.263991 â”† 1     â”† [[ 1.90314987    â”‚\n",
      "â”‚ -sick_1.wav       â”† -0.152634, â€¦ â”†     â”† k                 â”†          â”†       â”† 1.55816024 -0.0â€¦ â”‚\n",
      "â”‚                   â”† 0.006â€¦       â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P01_dysregulation â”† [0.088348,   â”† P01 â”† dysregulation-sic â”† 0.931995 â”† 2     â”† [[ 1.15689149    â”‚\n",
      "â”‚ -sick_2.wav       â”† 0.091385, â€¦  â”†     â”† k                 â”†          â”†       â”† 0.83036181  0.2â€¦ â”‚\n",
      "â”‚                   â”† -0.1295â€¦     â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P01_dysregulation â”† [0.035843,   â”† P01 â”† dysregulation-sic â”† 1.144989 â”† 3     â”† [[-0.23412235    â”‚\n",
      "â”‚ -sick_3.wav       â”† 0.024033, â€¦  â”†     â”† k                 â”†          â”†       â”† -0.22180939      â”‚\n",
      "â”‚                   â”† 0.21106â€¦     â”†     â”†                   â”†          â”†       â”† -0.4â€¦            â”‚\n",
      "â”‚ P01_dysregulation â”† [0.00676,    â”† P01 â”† dysregulation-sic â”† 3.647982 â”† 4     â”† [[ 0.51460581    â”‚\n",
      "â”‚ -sick_4.wav       â”† -0.000458, â€¦ â”†     â”† k                 â”†          â”†       â”† 0.31279042 -0.0â€¦ â”‚\n",
      "â”‚                   â”† 0.05534â€¦     â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P01_dysregulation â”† [0.028397,   â”† P01 â”† dysregulation-sic â”† 0.405986 â”† 5     â”† [[ 0.55980165    â”‚\n",
      "â”‚ -sick_5.wav       â”† 0.027649, â€¦  â”†     â”† k                 â”†          â”†       â”† 0.38610811 -0.2â€¦ â”‚\n",
      "â”‚                   â”† -0.3195â€¦     â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ â€¦                 â”† â€¦            â”† â€¦   â”† â€¦                 â”† â€¦        â”† â€¦     â”† â€¦                â”‚\n",
      "â”‚ P16_delighted_135 â”† [0.0, 0.0, â€¦ â”† P16 â”† delighted         â”† 1.046984 â”† 135   â”† [[-0.1850793     â”‚\n",
      "â”‚ .wav              â”† -0.013916]   â”†     â”†                   â”†          â”†       â”† 0.24888102  0.2â€¦ â”‚\n",
      "â”‚ P16_delighted_136 â”† [0.014069,   â”† P16 â”† delighted         â”† 0.643016 â”† 136   â”† [[ 0.35468619    â”‚\n",
      "â”‚ .wav              â”† 0.009094, â€¦  â”†     â”†                   â”†          â”†       â”† 0.4770178   0.6â€¦ â”‚\n",
      "â”‚                   â”† -0.0006â€¦     â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P16_delighted_137 â”† [-0.003715,  â”† P16 â”† delighted         â”† 0.773878 â”† 137   â”† [[-0.21028448    â”‚\n",
      "â”‚ .wav              â”† -0.004659, â€¦ â”†     â”†                   â”†          â”†       â”† -0.04781407      â”‚\n",
      "â”‚                   â”† 0.022â€¦       â”†     â”†                   â”†          â”†       â”† 0.1â€¦             â”‚\n",
      "â”‚ P16_delighted_138 â”† [-0.002249,  â”† P16 â”† delighted         â”† 0.747642 â”† 138   â”† [[ 0.69461725    â”‚\n",
      "â”‚ .wav              â”† -0.004126, â€¦ â”†     â”†                   â”†          â”†       â”† 0.9290602   0.8â€¦ â”‚\n",
      "â”‚                   â”† 0.018â€¦       â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P16_delighted_139 â”† [-0.013641,  â”† P16 â”† delighted         â”† 1.278005 â”† 139   â”† [[-0.20681652    â”‚\n",
      "â”‚ .wav              â”† -0.011871, â€¦ â”†     â”†                   â”†          â”†       â”† 0.06343726  0.0â€¦ â”‚\n",
      "â”‚                   â”† 0.010â€¦       â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "# set rename to False if files already renamed\n",
    "pipeline(\n",
    "    rename=True,\n",
    "    limit=None # processes all files \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
