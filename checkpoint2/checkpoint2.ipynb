{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 2 Notebook\n",
    "\n",
    "__TODO__:\n",
    "- fill this cell in with info, results, insights from our EDA \n",
    "- preprocess: create preprocessing pipeline, store all code into script, then run script to preprocess all data and store into pickle\n",
    "- analysis: need \"3 hypothesis tests\" to validate hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- imports ------------- #\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import scipy.signal as signal\n",
    "import polars as pl\n",
    "import soundfile as sf \n",
    "from typing import Union, List, Dict\n",
    "import json\n",
    "import time\n",
    "\n",
    "# ------------ macros ------------ #\n",
    "SAMPLE_RATE = 16e3\n",
    "ORG_CSV_PATH = 'ReCANVo/dataset_file_directory.csv'\n",
    "RENAME_CSV_PATH = 'ReCANVo/renamed_metadata.csv'\n",
    "AUDIO_DIR = 'ReCANVo/'\n",
    "\n",
    "\n",
    "# ----------------------- preprocessing functions ----------------------- #\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf  # Added soundfile for audio writing\n",
    "import scipy.signal as signal\n",
    "import os\n",
    "\n",
    "def save_audio_comparison(original_y: np.ndarray, \n",
    "                           cleaned_y: np.ndarray, \n",
    "                           sr: int, \n",
    "                           filename: str, \n",
    "                           output_dir: str = 'audio_comparisons') -> None:\n",
    "    \"\"\"\n",
    "    Save original and cleaned audio files for side-by-side comparison.\n",
    "\n",
    "    Parameters:\n",
    "        original_y (np.ndarray): Original audio time series\n",
    "        cleaned_y (np.ndarray): Cleaned audio time series\n",
    "        sr (int): Sampling rate\n",
    "        filename (str): Base filename for saved audio files\n",
    "        output_dir (str): Directory to save comparison audio files\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    original_path = os.path.join(output_dir, f\"{base_name}_original.wav\")\n",
    "    cleaned_path = os.path.join(output_dir, f\"{base_name}_cleaned.wav\")\n",
    "\n",
    "    sf.write(original_path, original_y, sr)\n",
    "    sf.write(cleaned_path, cleaned_y, sr)\n",
    "\n",
    "def clean_audio(y: np.ndarray, \n",
    "                sr: int, \n",
    "                denoise: bool = True, \n",
    "                remove_silence: bool = True,\n",
    "                normalize: bool = True,\n",
    "                min_silence_duration: float = 0.3,\n",
    "                silence_threshold: float = -40) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Enhanced audio cleaning function tailored for voice recordings of autistic individuals.\n",
    "\n",
    "    Parameters:\n",
    "        y (np.ndarray): Input audio time series\n",
    "        sr (int): Sampling rate\n",
    "        denoise (bool): Apply noise reduction\n",
    "        remove_silence (bool): Remove long silent segments\n",
    "        normalize (bool): Normalize audio amplitude\n",
    "        min_silence_duration (float): Minimum duration of silence to remove (in seconds)\n",
    "        silence_threshold (float): Decibel threshold for silence detection\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Cleaned audio time series\n",
    "    \"\"\"\n",
    "    cleaned_audio = y.copy()\n",
    "\n",
    "    if normalize:\n",
    "        cleaned_audio = librosa.util.normalize(cleaned_audio)\n",
    "\n",
    "    # Noise reduction using spectral gating\n",
    "    if denoise:\n",
    "        # Compute short-time Fourier transform (STFT)\n",
    "        stft = librosa.stft(cleaned_audio)\n",
    "        \n",
    "        # Compute magnitude and phase\n",
    "        mag, phase = librosa.magphase(stft)\n",
    "        \n",
    "        # Compute the noise threshold\n",
    "        noise_threshold = np.median(mag) * 0.5\n",
    "        \n",
    "        # Create a soft mask to reduce noise\n",
    "        mask = mag > noise_threshold\n",
    "        \n",
    "        # Apply the mask\n",
    "        cleaned_stft = stft * mask\n",
    "        \n",
    "        # Convert back to time domain\n",
    "        cleaned_audio = librosa.istft(cleaned_stft)\n",
    "\n",
    "    # Remove long silent segments\n",
    "    if remove_silence:\n",
    "        # Compute the frame size and hop length for silence detection\n",
    "        frame_length = int(sr * min_silence_duration)\n",
    "        hop_length = frame_length // 2\n",
    "\n",
    "        # Detect non-silent frames\n",
    "        non_silent_frames = librosa.effects.split(\n",
    "            cleaned_audio, \n",
    "            top_db=abs(silence_threshold), \n",
    "            frame_length=frame_length, \n",
    "            hop_length=hop_length\n",
    "        )\n",
    "\n",
    "        # Reconstruct audio from non-silent segments\n",
    "        cleaned_audio = np.concatenate([\n",
    "            cleaned_audio[start:end] for start, end in non_silent_frames\n",
    "        ])\n",
    "\n",
    "    # Apply gentle high-pass filter to reduce low-frequency noise\n",
    "    b, a = signal.butter(6, 80 / (sr/2), btype='high')\n",
    "    cleaned_audio = signal.filtfilt(b, a, cleaned_audio)\n",
    "\n",
    "    return cleaned_audio\n",
    "\n",
    "def load_audio_metadata(csv_path: str,\n",
    "                        audio_dir: str,\n",
    "                        limit: Union[int, None] = None,\n",
    "                        clean_audio_params: dict = None,\n",
    "                        save_comparisons: bool = False,\n",
    "                        comparison_dir: str = 'audio_comparisons') -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads audio files from directory and returns a DataFrame with cleaned waveform and metadata.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file containing data.\n",
    "        audio_dir (str): Directory where audio files are stored.\n",
    "        limit (int, optional): Number of rows to load. If None, loads all.\n",
    "        clean_audio_params (dict, optional): Parameters for audio cleaning.\n",
    "        save_comparisons (bool): Whether to save original vs cleaned audio files\n",
    "        comparison_dir (str): Directory to save comparison audio files\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame with columns: Filename, Audio, ID, Label, Duration, Index\n",
    "    \"\"\"\n",
    "    df = pl.read_csv(csv_path)\n",
    "    if limit:\n",
    "        df = df.head(limit)\n",
    "\n",
    "    # Default cleaning parameters if not provided\n",
    "    default_clean_params = {\n",
    "        'denoise': True,\n",
    "        'remove_silence': True,\n",
    "        'normalize': True,\n",
    "        'min_silence_duration': 0.3,\n",
    "        'silence_threshold': -40\n",
    "    }\n",
    "    clean_params = default_clean_params if clean_audio_params is None else {**default_clean_params, **clean_audio_params}\n",
    "\n",
    "    audio_data = []\n",
    "\n",
    "    if save_comparisons is True:\n",
    "        comparison_count = len(df)  \n",
    "    else:\n",
    "        comparison_count = 0  \n",
    "\n",
    "    for idx, row in enumerate(df.iter_rows(named=True)):\n",
    "        file_name = row['Filename']\n",
    "        file_path = os.path.join(audio_dir, file_name)\n",
    "\n",
    "        # Load original audio\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Clean audio\n",
    "        cleaned_y = clean_audio(y, sr, **clean_params)\n",
    "\n",
    "        if save_comparisons and idx < comparison_count:\n",
    "            save_audio_comparison(\n",
    "                original_y=y, \n",
    "                cleaned_y=cleaned_y, \n",
    "                sr=sr, \n",
    "                filename=file_name,\n",
    "                output_dir=comparison_dir\n",
    "            )\n",
    "        \n",
    "        duration = len(cleaned_y) / sr\n",
    "\n",
    "        audio_data.append((\n",
    "            file_name,\n",
    "            cleaned_y.tolist(),\n",
    "            row['ID'],\n",
    "            row['Label'],\n",
    "            duration,\n",
    "            row['Index']\n",
    "        ))\n",
    "\n",
    "    audio_df = pl.DataFrame(\n",
    "        audio_data,\n",
    "        schema=[\"Filename\", \"Audio\", \"ID\", \"Label\", \"Duration\", \"Index\"],\n",
    "        orient='row'\n",
    "    )\n",
    "\n",
    "    return audio_df\n",
    "\n",
    "\n",
    "def rename_audio_files(csv_path: str,\n",
    "                       audio_dir: str,\n",
    "                       output_csv: str = \"renamed_metadata.csv\") -> None:\n",
    "    \"\"\"\n",
    "    Renames audio files based on Participant and Label and saves new metadata.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the input metadata CSV.\n",
    "        audio_dir (str): Directory containing audio files.\n",
    "        output_csv (str): Filename for the output metadata CSV.\n",
    "    \"\"\"\n",
    "    df = pl.read_csv(csv_path)\n",
    "    renamed_files = []\n",
    "    file_counts = {}\n",
    "\n",
    "    for file in df.iter_rows(named=True):\n",
    "        org_name = file['Filename']\n",
    "        id = file['Participant']\n",
    "        label = file['Label']\n",
    "\n",
    "        key = (id, label)\n",
    "        file_counts[key] = file_counts.get(key, 0) + 1\n",
    "        index = file_counts[key]\n",
    "\n",
    "        new_name = f\"{id}_{label}_{index}.wav\"\n",
    "        old_path = os.path.join(audio_dir, org_name)\n",
    "        new_path = os.path.join(audio_dir, new_name)\n",
    "\n",
    "        if not os.path.exists(old_path):\n",
    "            print(f\"âŒ File not found: {old_path}. Skipping renaming process.\")\n",
    "            return  # Exit the function immediately if any file is missing\n",
    "\n",
    "        os.rename(old_path, new_path)\n",
    "        renamed_files.append((new_name, id, label, index))\n",
    "\n",
    "    # If renaming was successful, save the updated metadata\n",
    "    renamed_df = pl.DataFrame(renamed_files, schema=[\"Filename\", \"ID\", \"Label\", \"Index\"], orient=\"row\")\n",
    "    output_path = os.path.join(audio_dir, output_csv)\n",
    "    renamed_df.write_csv(output_path)\n",
    "    \n",
    "\n",
    "def compute_or_load_global_stats(ys: List[np.ndarray],\n",
    "                                 sr: int,\n",
    "                                 n_mels: int = 128,\n",
    "                                 method: str = \"zscore\",\n",
    "                                 stats_file: str = \"global_stats.json\",\n",
    "                                 force_recompute: bool = False) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Computes or loads global normalization stats for Mel spectrograms.\n",
    "\n",
    "    Parameters:\n",
    "        ys (List[np.ndarray]): List of raw audio waveforms.\n",
    "        sr (int): Sample rate.\n",
    "        n_mels (int): Number of Mel bands.\n",
    "        method (str): 'zscore' or 'minmax'.\n",
    "        stats_file (str): Path to save/load stats JSON.\n",
    "        force_recompute (bool): If True, recomputes even if file exists.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: Stats dictionary (mean/std or min/max).\n",
    "    \"\"\"\n",
    "\n",
    "    if not force_recompute and os.path.exists(stats_file):\n",
    "        print(f\"ðŸ—‚ï¸ Loading global stats from {stats_file}\")\n",
    "        with open(stats_file, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    print(f\"ðŸ“Š Computing global stats with method '{method}'...\")\n",
    "    all_values = []\n",
    "\n",
    "    for y in ys:\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "        S_db = librosa.power_to_db(S, ref=np.max)\n",
    "        all_values.append(S_db.flatten())\n",
    "\n",
    "    all_values = np.concatenate(all_values)\n",
    "    stats = {}\n",
    "\n",
    "    if method == \"zscore\":\n",
    "        stats = {\n",
    "            \"mean\": float(np.mean(all_values)),\n",
    "            \"std\": float(np.std(all_values))\n",
    "        }\n",
    "    elif method == \"minmax\":\n",
    "        stats = {\n",
    "            \"min\": float(np.min(all_values)),\n",
    "            \"max\": float(np.max(all_values))\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Use 'zscore' or 'minmax'.\")\n",
    "\n",
    "    # Save stats to file\n",
    "    with open(stats_file, \"w\") as f:\n",
    "        json.dump(stats, f)\n",
    "        print(f\"ðŸ’¾ Saved global stats to {stats_file}\")\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "\n",
    "def audio_to_spectrogram(y: np.ndarray,\n",
    "                         sr: int,\n",
    "                         n_mels: int = 128,\n",
    "                         target_length: int = 128,\n",
    "                         normalization: str = \"minmax\",\n",
    "                         normalize_scope: str = \"sample\",  # \"sample\" or \"global\"\n",
    "                         global_stats: dict = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts a raw audio waveform into a normalized, fixed-size Mel spectrogram.\n",
    "\n",
    "    Parameters:\n",
    "        y (np.ndarray): Raw audio waveform.\n",
    "        sr (int): Sample rate of the audio.\n",
    "        n_mels (int): Number of Mel bands.\n",
    "        target_length (int): Number of time steps to pad/crop to.\n",
    "        normalization (str): 'minmax' or 'zscore'.\n",
    "        normalize_scope (str): 'sample' for per-sample normalization,\n",
    "                               'global' for dataset-wide using global_stats.\n",
    "        global_stats (dict): Required if normalize_scope='global'. Should contain\n",
    "                             'mean' and 'std' or 'min' and 'max'.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Mel spectrogram of shape (n_mels, target_length).\n",
    "    \"\"\"\n",
    "\n",
    "    def _normalize(S_db: np.ndarray, method: str, scope: str, stats: dict = None):\n",
    "        if scope == \"sample\":\n",
    "            if method == \"minmax\":\n",
    "                return (S_db - S_db.min()) / (S_db.max() - S_db.min())\n",
    "            elif method == \"zscore\":\n",
    "                mean = np.mean(S_db)\n",
    "                std = np.std(S_db)\n",
    "                return (S_db - mean) / std\n",
    "        elif scope == \"global\":\n",
    "            if stats is None:\n",
    "                raise ValueError(\"Global normalization requires global_stats.\")\n",
    "            if method == \"minmax\":\n",
    "                return (S_db - stats[\"min\"]) / (stats[\"max\"] - stats[\"min\"])\n",
    "            elif method == \"zscore\":\n",
    "                return (S_db - stats[\"mean\"]) / stats[\"std\"]\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported normalization scope. Use 'sample' or 'global'.\")\n",
    "\n",
    "    def _pad_or_crop(S: np.ndarray, target_len: int):\n",
    "        current_len = S.shape[1]\n",
    "        if current_len < target_len:\n",
    "            pad_width = target_len - current_len\n",
    "            return np.pad(S, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            return S[:, :target_len]\n",
    "\n",
    "    # Compute Mel spectrogram and convert to dB\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    # Normalize\n",
    "    S_norm = _normalize(S_db, method=normalization, scope=normalize_scope, stats=global_stats)\n",
    "\n",
    "    # Fix shape\n",
    "    S_fixed = _pad_or_crop(S_norm, target_len=target_length)\n",
    "\n",
    "    return S_fixed\n",
    "\n",
    "\n",
    "def pipeline(rename: bool=False, \n",
    "             limit: Union[int, None] = None,\n",
    "             clean_audio_params: dict = None,\n",
    "             save_comparisons: bool = False):\n",
    "    \"\"\"\n",
    "    Pipeline to run all preprocessing functions with timing and optional audio cleaning.\n",
    "    \"\"\"\n",
    "    print(\"ðŸš€ Starting preprocessing pipeline...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    # Step 1: Rename files\n",
    "    if rename:\n",
    "        t0 = time.time()\n",
    "        rename_audio_files(\n",
    "            csv_path=ORG_CSV_PATH,\n",
    "            audio_dir=AUDIO_DIR,\n",
    "        )\n",
    "        print(f\"ðŸ“ rename_audio_files completed in {time.time() - t0:.2f} seconds\")\n",
    "\n",
    "    # Step 2: Load audio metadata with cleaning\n",
    "    t0 = time.time()\n",
    "    df = load_audio_metadata(\n",
    "        csv_path=RENAME_CSV_PATH,\n",
    "        audio_dir=AUDIO_DIR,\n",
    "        limit=limit,\n",
    "        clean_audio_params=clean_audio_params,\n",
    "        save_comparisons=save_comparisons\n",
    "    )\n",
    "    print(f\"â³ load_audio_metadata completed in {time.time() - t0:.2f} seconds\")\n",
    "\n",
    "    # Step 3: Compute or load global stats\n",
    "    t0 = time.time()\n",
    "    stats = compute_or_load_global_stats(df[\"Audio\"].to_numpy(), sr=SAMPLE_RATE)\n",
    "    print(f\"ðŸ§® compute_or_load_global_stats completed in {time.time() - t0:.2f} seconds\")\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ Computed Statistics:\")\n",
    "    for k, v in stats.items(): \n",
    "        print(f\"  {k}: {v}\")\n",
    "    print()\n",
    "\n",
    "    # Step 4: Compute spectrograms\n",
    "    t0 = time.time()\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"Audio\").map_elements(lambda y: audio_to_spectrogram(\n",
    "            y=np.array(y),\n",
    "            sr=SAMPLE_RATE,\n",
    "            normalization='zscore',\n",
    "            normalize_scope='global',\n",
    "            global_stats=stats\n",
    "        ), return_dtype=pl.Object).alias(\"Spectrogram\")\n",
    "    ])\n",
    "    print(f\"ðŸ”Š Spectrogram generation completed in {time.time() - t0:.2f} seconds\")\n",
    "\n",
    "    # Done\n",
    "    print(f\"\\nðŸ Full pipeline completed in {time.time() - start:.2f} seconds\\n\")\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting preprocessing pipeline...\n",
      "â³ load_audio_metadata completed in 161.51 seconds\n",
      "ðŸ—‚ï¸ Loading global stats from global_stats.json\n",
      "ðŸ§® compute_or_load_global_stats completed in 0.16 seconds\n",
      "\n",
      "ðŸ“ˆ Computed Statistics:\n",
      "  mean: -55.975612227106474\n",
      "  std: 18.55726476893056\n",
      "\n",
      "ðŸ”Š Spectrogram generation completed in 32.23 seconds\n",
      "\n",
      "ðŸ Full pipeline completed in 193.90 seconds\n",
      "\n",
      "shape: (7_077, 7)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ Filename          â”† Audio        â”† ID  â”† Label             â”† Duration â”† Index â”† Spectrogram      â”‚\n",
      "â”‚ ---               â”† ---          â”† --- â”† ---               â”† ---      â”† ---   â”† ---              â”‚\n",
      "â”‚ str               â”† list[f64]    â”† str â”† str               â”† f64      â”† i64   â”† object           â”‚\n",
      "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ P01_dysregulation â”† [-0.107696,  â”† P01 â”† dysregulation-sic â”† 0.263991 â”† 1     â”† [[ 1.7136524     â”‚\n",
      "â”‚ -sick_1.wav       â”† -0.120435, â€¦ â”†     â”† k                 â”†          â”†       â”† 1.54897187  0.8â€¦ â”‚\n",
      "â”‚                   â”† 0.004â€¦       â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P01_dysregulation â”† [0.145757,   â”† P01 â”† dysregulation-sic â”† 0.931995 â”† 2     â”† [[ 1.12985372    â”‚\n",
      "â”‚ -sick_2.wav       â”† 0.148597, â€¦  â”†     â”† k                 â”†          â”†       â”† 0.95378244  0.4â€¦ â”‚\n",
      "â”‚                   â”† 0.00491â€¦     â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P01_dysregulation â”† [0.034168,   â”† P01 â”† dysregulation-sic â”† 1.144989 â”† 3     â”† [[ 0.31567814    â”‚\n",
      "â”‚ -sick_3.wav       â”† 0.022339, â€¦  â”†     â”† k                 â”†          â”†       â”† 0.21322916 -0.4â€¦ â”‚\n",
      "â”‚                   â”† 0.05369â€¦     â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P01_dysregulation â”† [-0.005132,  â”† P01 â”† dysregulation-sic â”† 3.647982 â”† 4     â”† [[ 0.36459158    â”‚\n",
      "â”‚ -sick_4.wav       â”† -0.012268, â€¦ â”†     â”† k                 â”†          â”†       â”† 0.38200755  0.0â€¦ â”‚\n",
      "â”‚                   â”† 0.001â€¦       â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P01_dysregulation â”† [-0.002284,  â”† P01 â”† dysregulation-sic â”† 0.405986 â”† 5     â”† [[ 1.21694593    â”‚\n",
      "â”‚ -sick_5.wav       â”† -0.002782, â€¦ â”†     â”† k                 â”†          â”†       â”† 1.03654392  0.2â€¦ â”‚\n",
      "â”‚                   â”† -0.07â€¦       â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ â€¦                 â”† â€¦            â”† â€¦   â”† â€¦                 â”† â€¦        â”† â€¦     â”† â€¦                â”‚\n",
      "â”‚ P16_delighted_135 â”† [0.000051,   â”† P16 â”† delighted         â”† 1.046984 â”† 135   â”† [[-4.64737797e-0 â”‚\n",
      "â”‚ .wav              â”† 0.000053, â€¦  â”†     â”†                   â”†          â”†       â”† 1 -1.08887263eâ€¦  â”‚\n",
      "â”‚                   â”† -0.0047â€¦     â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P16_delighted_136 â”† [0.017027,   â”† P16 â”† delighted         â”† 0.643016 â”† 136   â”† [[ 1.08366406    â”‚\n",
      "â”‚ .wav              â”† 0.005405, â€¦  â”†     â”†                   â”†          â”†       â”† 0.90978611  0.3â€¦ â”‚\n",
      "â”‚                   â”† 0.01137â€¦     â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P16_delighted_137 â”† [0.008868,   â”† P16 â”† delighted         â”† 0.773878 â”† 137   â”† [[ 0.6198277     â”‚\n",
      "â”‚ .wav              â”† 0.006852, â€¦  â”†     â”†                   â”†          â”†       â”† 0.43539034 -0.0â€¦ â”‚\n",
      "â”‚                   â”† -0.0060â€¦     â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P16_delighted_138 â”† [0.01538,    â”† P16 â”† delighted         â”† 0.747642 â”† 138   â”† [[ 0.57094528    â”‚\n",
      "â”‚ .wav              â”† 0.010325, â€¦  â”†     â”†                   â”†          â”†       â”† 0.31298055 -0.1â€¦ â”‚\n",
      "â”‚                   â”† -0.01283â€¦    â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â”‚ P16_delighted_139 â”† [-0.001161,  â”† P16 â”† delighted         â”† 1.278005 â”† 139   â”† [[ 0.66027667    â”‚\n",
      "â”‚ .wav              â”† 0.001708, â€¦  â”†     â”†                   â”†          â”†       â”† 0.47639898 -0.1â€¦ â”‚\n",
      "â”‚                   â”† -0.001â€¦      â”†     â”†                   â”†          â”†       â”†                  â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "custom_clean_params = {\n",
    "    'denoise': False,\n",
    "    'remove_silence': False,\n",
    "    'min_silence_duration': 0.5,\n",
    "    'silence_threshold': -35\n",
    "}\n",
    "\n",
    "df = pipeline(\n",
    "    rename=False, \n",
    "    limit=None,\n",
    "    clean_audio_params=custom_clean_params,\n",
    "    save_comparisons=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
