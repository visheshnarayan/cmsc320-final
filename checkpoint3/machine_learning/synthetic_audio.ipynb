{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from pathlib import Path\n",
    "import soundfile as sf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_audio_data(\n",
    "    df: pl.DataFrame,\n",
    "    target_count_per_label: int = 150,\n",
    "    output_path: str = \"balanced_audio_data.parquet\",\n",
    "    save_samples: int = 0,  # Number of samples to save (0 = none)\n",
    "    sample_rate: int = 44100,  # Default sample rate\n",
    "    output_dir: str = \"synthetic_samples\",\n",
    "    batch_size: int = 50  # Process in batches to reduce memory usage\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate synthetic audio data to balance class distribution, using batch processing\n",
    "    to reduce memory consumption.\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    if save_samples > 0 and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created directory {output_dir} for synthetic audio samples\")\n",
    "    \n",
    "    # Get label counts and determine how many samples to generate for each label\n",
    "    label_counts = df.group_by(\"Label\").agg(pl.count()).sort(\"count\")\n",
    "    print(f\"Original label distribution:\\n{label_counts}\")\n",
    "    \n",
    "    # Create a dictionary for needed synthetic samples per label\n",
    "    synthetic_needs = {}\n",
    "    for label, count in zip(label_counts[\"Label\"], label_counts[\"count\"]):\n",
    "        if count < target_count_per_label:\n",
    "            synthetic_needs[label] = target_count_per_label - count\n",
    "    \n",
    "    # No need to create label_to_examples for the entire dataset at once\n",
    "    # We'll fetch examples for each label as needed\n",
    "    \n",
    "    # First, create a copy of the original dataframe to avoid modification issues\n",
    "    combined_df = df.clone()\n",
    "    start_index = int(df[\"Index\"].max()) + 1\n",
    "    samples_saved = 0\n",
    "    \n",
    "    # Process each label that needs synthetic data\n",
    "    for label, examples_needed in synthetic_needs.items():\n",
    "        print(f\"Generating {examples_needed} synthetic samples for label '{label}'\")\n",
    "        \n",
    "        # Get source samples for this label\n",
    "        label_samples = df.filter(pl.col(\"Label\") == label)\n",
    "        \n",
    "        # Process in batches to reduce memory usage\n",
    "        for batch_start in range(0, examples_needed, batch_size):\n",
    "            batch_end = min(batch_start + batch_size, examples_needed)\n",
    "            batch_size_actual = batch_end - batch_start\n",
    "            print(f\"Processing batch {batch_start+1}-{batch_end} for label '{label}'\")\n",
    "            \n",
    "            batch_rows = []\n",
    "            for i in range(batch_size_actual):\n",
    "                try:\n",
    "                    new_index = start_index + batch_start + i\n",
    "                    synthetic_sample = generate_synthetic_sample(\n",
    "                        label_samples, \n",
    "                        label,\n",
    "                        new_index\n",
    "                    )\n",
    "                    batch_rows.append(synthetic_sample)\n",
    "                    \n",
    "                    # Save synthetic samples as WAV files if requested\n",
    "                    if save_samples > 0 and samples_saved < save_samples:\n",
    "                        # Get the audio data and filename\n",
    "                        audio_data = np.array(synthetic_sample[\"Audio\"], dtype=np.float32)\n",
    "                        filename = synthetic_sample[\"Filename\"]\n",
    "                        wav_path = os.path.join(output_dir, f\"sample_{samples_saved+1}_{filename}\")\n",
    "                        \n",
    "                        # Save as WAV file\n",
    "                        try:\n",
    "                            sf.write(wav_path, audio_data, sample_rate)\n",
    "                            print(f\"Saved synthetic audio sample {samples_saved+1} to {wav_path}\")\n",
    "                            samples_saved += 1\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error saving audio sample: {e}\")\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating synthetic sample for label '{label}': {e}\")\n",
    "            \n",
    "            # Convert batch to dataframe and append to combined dataframe\n",
    "            if batch_rows:\n",
    "                try:\n",
    "                    batch_df = pl.DataFrame(batch_rows)\n",
    "                    \n",
    "                    # Make sure synthetic data has the same columns as original\n",
    "                    for col in df.columns:\n",
    "                        if col not in batch_df.columns:\n",
    "                            # Add missing column with default values\n",
    "                            if col in [\"Audio\"]:\n",
    "                                batch_df = batch_df.with_columns(pl.lit([0.0]).repeat(len(batch_df)).alias(col))\n",
    "                            else:\n",
    "                                batch_df = batch_df.with_columns(pl.lit(None).alias(col))\n",
    "                    \n",
    "                    # Keep only columns from the original dataframe\n",
    "                    batch_df = batch_df.select(df.columns)\n",
    "                    \n",
    "                    # Append to combined dataframe\n",
    "                    combined_df = pl.concat([combined_df, batch_df])\n",
    "                    \n",
    "                    # Periodically save intermediate results to reduce memory pressure\n",
    "                    if batch_end % (batch_size * 3) == 0 or batch_end == examples_needed:\n",
    "                        temp_output = f\"{output_path}.temp\"\n",
    "                        combined_df.write_parquet(temp_output)\n",
    "                        print(f\"Saved intermediate balanced dataset to {temp_output}\")\n",
    "                        \n",
    "                        # To reduce memory, we could optionally reload the data\n",
    "                        # combined_df = pl.read_parquet(temp_output)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing batch: {e}\")\n",
    "                    if 'batch_df' in locals():\n",
    "                        print(f\"Batch width: {len(batch_df.columns)}\")\n",
    "    \n",
    "    # Save final combined dataset\n",
    "    combined_df.write_parquet(output_path)\n",
    "    print(f\"Saved balanced dataset to {output_path}\")\n",
    "    \n",
    "    # Show final distribution\n",
    "    new_label_counts = combined_df.group_by(\"Label\").agg(pl.count()).sort(\"count\")\n",
    "    print(f\"New label distribution:\\n{new_label_counts}\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def generate_synthetic_sample(\n",
    "    source_samples: pl.DataFrame,\n",
    "    label: str,\n",
    "    new_index: int\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Generate a single synthetic audio sample by mixing multiple source samples.\n",
    "    Memory optimized to avoid large array allocations where possible.\n",
    "    \"\"\"\n",
    "    num_samples = len(source_samples)\n",
    "    num_samples_to_mix = random.randint(2, min(3, num_samples))\n",
    "    sample_indices = random.sample(range(num_samples), num_samples_to_mix)\n",
    "    \n",
    "    # Get selected samples\n",
    "    selected_samples = [source_samples.row(i, named=True) for i in sample_indices]\n",
    "    first_sample = selected_samples[0]\n",
    "    \n",
    "    # Find the audio column\n",
    "    audio_column = None\n",
    "    for col in [\"Audio\"]:\n",
    "        if col in first_sample:\n",
    "            audio_column = col\n",
    "            break\n",
    "    \n",
    "    # Create new filename\n",
    "    filename = first_sample.get(\"Filename\", \"\")\n",
    "    if filename and \"_\" in filename:\n",
    "        participant_id = filename.split(\"_\")[0]\n",
    "    else:\n",
    "        participant_id = \"P00\" \n",
    "    \n",
    "    new_filename = f\"{participant_id}_{label}_synthetic_{new_index}.wav\"\n",
    "    \n",
    "    # Process audio data with memory efficiency in mind\n",
    "    audio_data = first_sample.get(audio_column, [])\n",
    "    if not isinstance(audio_data, list):\n",
    "        try:\n",
    "            audio_data = list(audio_data)\n",
    "        except:\n",
    "            audio_data = []\n",
    "    \n",
    "    # Find minimum audio length to avoid index errors\n",
    "    min_audio_length = min(len(sample.get(audio_column, [])) \n",
    "                          for sample in selected_samples \n",
    "                          if hasattr(sample.get(audio_column, []), '__len__'))\n",
    "    \n",
    "    # Pre-allocate the synthetic audio array for better memory efficiency\n",
    "    synthetic_audio = np.zeros(min_audio_length, dtype=np.float32)\n",
    "    \n",
    "    # Generate synthetic audio in chunks for memory efficiency\n",
    "    chunk_size = 1000  # Process audio in chunks to reduce memory usage\n",
    "    \n",
    "    for chunk_start in range(0, min_audio_length, chunk_size):\n",
    "        chunk_end = min(chunk_start + chunk_size, min_audio_length)\n",
    "        \n",
    "        for i in range(chunk_start, chunk_end):\n",
    "            try:\n",
    "                values = []\n",
    "                for sample in selected_samples:\n",
    "                    sample_audio = sample.get(audio_column, [])\n",
    "                    if i < len(sample_audio):\n",
    "                        values.append(sample_audio[i])\n",
    "                \n",
    "                if values:\n",
    "                    weights = np.random.dirichlet(np.ones(len(values)))\n",
    "                    avg_value = sum(v * w for v, w in zip(values, weights))\n",
    "                    synthetic_audio[i] = float(avg_value) + np.random.normal(0, 0.02)\n",
    "                else:\n",
    "                    synthetic_audio[i] = np.random.normal(0, 0.02)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing audio at index {i}: {e}\")\n",
    "                synthetic_audio[i] = 0.0\n",
    "    \n",
    "    # Convert back to list for polars compatibility\n",
    "    synthetic_audio = synthetic_audio.tolist()\n",
    "    \n",
    "    # Get metadata from first sample\n",
    "    id_value = first_sample.get(\"ID\", participant_id)\n",
    "    \n",
    "    # Calculate duration\n",
    "    duration_values = [float(sample.get(\"Duration\", 1.0)) for sample in selected_samples]\n",
    "    avg_duration = sum(duration_values) / len(duration_values) if duration_values else 1.0\n",
    "    new_duration = avg_duration * random.uniform(0.9, 1.1)\n",
    "    \n",
    "    # Process spectrogram more efficiently\n",
    "    new_spectrogram = process_spectrogram_efficiently(selected_samples)\n",
    "    \n",
    "    # Create result dictionary\n",
    "    result = {\n",
    "        \"Filename\": new_filename,\n",
    "        \"Audio\": synthetic_audio,\n",
    "        \"ID\": id_value,\n",
    "        \"Label\": label,\n",
    "        \"Duration\": float(new_duration),\n",
    "        \"Index\": int(new_index),\n",
    "        \"Spectrogram\": new_spectrogram\n",
    "    }\n",
    "    \n",
    "    # Ensure audio column is set\n",
    "    result[audio_column] = synthetic_audio\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def process_spectrogram_efficiently(selected_samples: List[Dict]) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Process spectrograms more efficiently to reduce memory usage.\n",
    "    \"\"\"\n",
    "    first_sample = selected_samples[0]\n",
    "    base_spectrogram = first_sample.get(\"Spectrogram\", [])\n",
    "    \n",
    "    if not base_spectrogram:\n",
    "        return []\n",
    "    \n",
    "    # Get dimensions for new spectrogram\n",
    "    spec_height = len(base_spectrogram)\n",
    "    if spec_height == 0:\n",
    "        return []\n",
    "    \n",
    "    # Find a valid row to determine width\n",
    "    for sample in selected_samples:\n",
    "        spec = sample.get(\"Spectrogram\", [])\n",
    "        if spec and len(spec) > 0 and len(spec[0]) > 0:\n",
    "            first_row_len = len(spec[0])\n",
    "            break\n",
    "    else:\n",
    "        # Default if no valid row found\n",
    "        first_row_len = 10 if base_spectrogram and len(base_spectrogram) > 0 else 10\n",
    "    \n",
    "    # Pre-allocate spectrogram\n",
    "    new_spectrogram = []\n",
    "    \n",
    "    # Process row by row\n",
    "    for row_idx in range(spec_height):\n",
    "        available_rows = []\n",
    "        for sample in selected_samples:\n",
    "            spec = sample.get(\"Spectrogram\", [])\n",
    "            if row_idx < len(spec) and spec[row_idx]:\n",
    "                available_rows.append(spec[row_idx])\n",
    "        \n",
    "        if not available_rows:\n",
    "            if new_spectrogram:\n",
    "                # Copy last row with some noise\n",
    "                new_row = [float(v) + np.random.normal(0, 0.1) for v in new_spectrogram[-1]]\n",
    "            else:\n",
    "                # Create random row\n",
    "                new_row = [np.random.normal(0, 0.1) for _ in range(first_row_len)]\n",
    "        else:\n",
    "            # Find minimum column length to avoid index errors\n",
    "            max_col = min(len(row) for row in available_rows if row)\n",
    "            \n",
    "            # Create new row\n",
    "            new_row = []\n",
    "            for col_idx in range(max_col):\n",
    "                try:\n",
    "                    values = [float(row[col_idx]) for row in available_rows if col_idx < len(row)]\n",
    "                    if values:\n",
    "                        weights = np.random.dirichlet(np.ones(len(values)))\n",
    "                        avg_value = sum(v * w for v, w in zip(values, weights))\n",
    "                        new_row.append(float(avg_value) + np.random.normal(0, 0.05))\n",
    "                    else:\n",
    "                        new_row.append(np.random.normal(0, 0.1))\n",
    "                except Exception:\n",
    "                    new_row.append(np.random.normal(0, 0.1))\n",
    "        \n",
    "        new_spectrogram.append(new_row)\n",
    "    \n",
    "    return new_spectrogram\n",
    "\n",
    "\n",
    "def load_and_balance_audio_data(\n",
    "    input_path: str,\n",
    "    target_count: int = 150,\n",
    "    output_path: str = \"balanced_audio_data.parquet\",\n",
    "    save_samples: int = 0,\n",
    "    sample_rate: int = 44100,\n",
    "    output_dir: str = \"synthetic_samples\",\n",
    "    batch_size: int = 50\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load audio data and balance the dataset using memory-efficient batched processing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the data\n",
    "        print(f\"Loading data from {input_path}\")\n",
    "        df = pl.read_parquet(input_path)\n",
    "        \n",
    "        # Print column names and sample data for debugging\n",
    "        print(f\"Available columns: {df.columns}\")\n",
    "        print(f\"Number of rows: {len(df)}\")\n",
    "        \n",
    "        # Generate synthetic data and save\n",
    "        return generate_synthetic_audio_data(\n",
    "            df, \n",
    "            target_count, \n",
    "            output_path,\n",
    "            save_samples=save_samples,\n",
    "            sample_rate=sample_rate,\n",
    "            output_dir=output_dir,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error in load_and_balance_audio_data: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /Users/shivam/Documents/ComSci/Classes/CMSC320/cmsc320-final/checkpoint2/processed_data.parquet\n",
      "Available columns: ['Filename', 'Audio', 'ID', 'Label', 'Duration', 'Index', 'Spectrogram']\n",
      "Number of rows: 7077\n",
      "Original label distribution:\n",
      "shape: (22, 2)\n",
      "┌──────────────┬───────┐\n",
      "│ Label        ┆ count │\n",
      "│ ---          ┆ ---   │\n",
      "│ str          ┆ u32   │\n",
      "╞══════════════╪═══════╡\n",
      "│ greeting     ┆ 3     │\n",
      "│ hunger       ┆ 4     │\n",
      "│ tablet       ┆ 7     │\n",
      "│ glee         ┆ 8     │\n",
      "│ laugh        ┆ 8     │\n",
      "│ …            ┆ …     │\n",
      "│ social       ┆ 634   │\n",
      "│ dysregulated ┆ 704   │\n",
      "│ delighted    ┆ 1272  │\n",
      "│ frustrated   ┆ 1536  │\n",
      "│ selftalk     ┆ 1885  │\n",
      "└──────────────┴───────┘\n",
      "Generating 2 synthetic samples for label 'greeting'\n",
      "Processing batch 1-2 for label 'greeting'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6f/pf1hcqbd54109fj6nzc0sw5m0000gn/T/ipykernel_49786/971703880.py:20: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "  label_counts = df.group_by(\"Label\").agg(pl.count()).sort(\"count\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved synthetic audio sample 1 to synthetic_samples/sample_1_P11_greeting_synthetic_782.wav\n",
      "Saved synthetic audio sample 2 to synthetic_samples/sample_2_P11_greeting_synthetic_783.wav\n"
     ]
    }
   ],
   "source": [
    "input_file = \"../checkpoint2/processed_data.parquet\"  # Path to your input data\n",
    "    \n",
    "# Set target count per label\n",
    "target_samples_per_label = 150  # Adjust as needed\n",
    "\n",
    "# Load, balance, and save\n",
    "balanced_df = load_and_balance_audio_data(\n",
    "    input_file, \n",
    "    target_samples_per_label,\n",
    "    \"balanced_audio_data.parquet\",\n",
    "    save_samples=0, \n",
    ")\n",
    "    \n",
    "print(f\"Original data shape: {pl.read_parquet(input_file).shape}\")\n",
    "print(f\"Balanced data shape: {balanced_df.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
