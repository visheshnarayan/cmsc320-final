{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf5d4a1",
   "metadata": {},
   "source": [
    "vishesh and shivam \n",
    "\n",
    "defeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b63d22a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "import random\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6db15876",
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "parquet: File out of specification: The file must end with PAR1\n\nThis error occurred with the following context stack:\n\t[1] 'parquet scan'\n\t[2] 'sink'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mComputeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopen_parquet\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) -> pl.DataFrame:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pl.read_parquet(path)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df = \u001b[43mopen_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Users/shivam/Documents/ComSci/Classes/CMSC320/cmsc320-final/checkpoint3/machine_learning/balanced_audio_data.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m df\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mopen_parquet\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopen_parquet\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) -> pl.DataFrame:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ComSci/Classes/CMSC320/cmsc320-final/.venv/lib/python3.13/site-packages/polars/_utils/deprecation.py:119\u001b[39m, in \u001b[36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> T:\n\u001b[32m    116\u001b[39m     _rename_keyword_argument(\n\u001b[32m    117\u001b[39m         old_name, new_name, kwargs, function.\u001b[34m__qualname__\u001b[39m, version\n\u001b[32m    118\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ComSci/Classes/CMSC320/cmsc320-final/.venv/lib/python3.13/site-packages/polars/_utils/deprecation.py:119\u001b[39m, in \u001b[36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> T:\n\u001b[32m    116\u001b[39m     _rename_keyword_argument(\n\u001b[32m    117\u001b[39m         old_name, new_name, kwargs, function.\u001b[34m__qualname__\u001b[39m, version\n\u001b[32m    118\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ComSci/Classes/CMSC320/cmsc320-final/.venv/lib/python3.13/site-packages/polars/io/parquet/functions.py:252\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(source, columns, n_rows, row_index_name, row_index_offset, parallel, use_statistics, hive_partitioning, glob, schema, hive_schema, try_parse_hive_dates, rechunk, low_memory, storage_options, credential_provider, retries, use_pyarrow, pyarrow_options, memory_map, include_file_paths, allow_missing_columns)\u001b[39m\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    250\u001b[39m         lf = lf.select(columns)\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ComSci/Classes/CMSC320/cmsc320-final/.venv/lib/python3.13/site-packages/polars/_utils/deprecation.py:93\u001b[39m, in \u001b[36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33min-memory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstreaming\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ComSci/Classes/CMSC320/cmsc320-final/.venv/lib/python3.13/site-packages/polars/lazyframe/frame.py:2188\u001b[39m, in \u001b[36mLazyFrame.collect\u001b[39m\u001b[34m(self, type_coercion, _type_check, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, _check_order, _eager, **_kwargs)\u001b[39m\n\u001b[32m   2186\u001b[39m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[32m   2187\u001b[39m callback = _kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mpost_opt_callback\u001b[39m\u001b[33m\"\u001b[39m, callback)\n\u001b[32m-> \u001b[39m\u001b[32m2188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mComputeError\u001b[39m: parquet: File out of specification: The file must end with PAR1\n\nThis error occurred with the following context stack:\n\t[1] 'parquet scan'\n\t[2] 'sink'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def open_parquet(path: str) -> pl.DataFrame:\n",
    "    return pl.read_parquet(path)\n",
    "\n",
    "df = open_parquet(\"\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417269ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AudioAttention(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(AudioAttention, self).__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1, bias=False)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, encoder_outputs):\n",
    "        # Compute attention scores\n",
    "        attention_scores = self.attention(encoder_outputs)\n",
    "        attention_weights = self.softmax(attention_scores)\n",
    "        \n",
    "        # Apply attention weights\n",
    "        context_vector = torch.sum(attention_weights * encoder_outputs, dim=1)\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "class AudioClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(AudioClassifier, self).__init__()\n",
    "        self.cnn = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.attention = AudioAttention(input_dim, hidden_dim * 2)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature extraction with CNN\n",
    "        x = self.cnn(x)\n",
    "        x = torch.relu(x)\n",
    "        x = x.permute(0, 2, 1)  # Prepare for RNN (batch, seq_len, feature_dim)\n",
    "\n",
    "        # Sequence modeling with RNN\n",
    "        rnn_outputs, _ = self.rnn(x)\n",
    "\n",
    "        # Apply attention\n",
    "        context_vector, attention_weights = self.attention(rnn_outputs)\n",
    "\n",
    "        # Classification\n",
    "        logits = self.fc(context_vector)\n",
    "        return logits, attention_weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
